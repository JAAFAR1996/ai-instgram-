/**
 * ===============================================
 * Instagram AI Service Tests
 * Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ø´Ø§Ù…Ù„Ø© Ù„Ø®Ø¯Ù…Ø© Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ù„Ø¥Ù†Ø³ØªÙ‚Ø±Ø§Ù…
 * ===============================================
 */

import { describe, test, expect, beforeEach, afterEach, jest } from 'bun:test';
import OpenAI from 'openai';

import {
  InstagramAIService,
  getInstagramAIService,
  type InstagramAIResponse,
  type InstagramContext,
  type MediaRecommendation
} from './instagram-ai.js';

// Mock dependencies
jest.mock('openai');
jest.mock('./logger.js', () => ({
  createLogger: jest.fn(() => ({
    error: jest.fn(),
    info: jest.fn(),
    warn: jest.fn(),
    debug: jest.fn()
  }))
}));

jest.mock('../database/connection.js', () => ({
  getDatabase: jest.fn(() => ({
    getSQL: jest.fn(() => jest.fn())
  }))
}));

const mockOpenAI = {
  chat: {
    completions: {
      create: jest.fn()
    }
  }
};

describe('ðŸ“± Instagram AI Service Tests', () => {
  let instagramAIService: InstagramAIService;
  let mockSQL: jest.Mock;

  const sampleInstagramContext: InstagramContext = {
    merchantId: 'merchant-123',
    customerId: 'customer-456',
    platform: 'instagram' as const,
    stage: 'PRODUCT_INQUIRY' as const,
    cart: [],
    preferences: {},
    conversationHistory: [
      {
        role: 'user',
        content: 'Ù…Ø±Ø­Ø¨Ø§ ðŸ‘‹ Ø´ÙØª Ø§Ù„Ø³ØªÙˆØ±ÙŠØŒ Ø§Ù„Ù…Ù†ØªØ¬ Ø­Ù„Ùˆ ÙƒØ«ÙŠØ±',
        timestamp: new Date()
      }
    ],
    interactionType: 'story_reply',
    mediaContext: {
      mediaId: 'story-123',
      mediaType: 'photo',
      caption: 'Ù…Ù†ØªØ¬Ø§ØªÙ†Ø§ Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø© ðŸ”¥',
      hashtags: ['#Ø¬Ø¯ÙŠØ¯', '#ØªØ±Ù†Ø¯']
    },
    customerProfile: {
      name: 'Ø³Ø§Ø±Ø© Ø£Ø­Ù…Ø¯',
      instagram: '@sara_ahmed',
      previousOrders: 1,
      averageOrderValue: 120,
      preferredCategories: ['fashion'],
      lastInteraction: new Date()
    },
    merchantSettings: {
      businessName: 'Ø¨ÙˆØªÙŠÙƒ Ø§Ù„Ø¹ØµØ±ÙŠØ©',
      businessCategory: 'fashion',
      workingHours: { start: '10:00', end: '22:00' },
      paymentMethods: ['cash', 'zain_cash'],
      deliveryFees: { default: 3000 },
      autoResponses: {}
    },
    visualPreferences: {
      colorScheme: ['pink', 'gold'],
      aestheticStyle: 'minimalist',
      contentType: ['photos', 'reels']
    }
  };

  beforeEach(() => {
    jest.clearAllMocks();
    
    // Setup environment variables
    process.env.OPENAI_API_KEY = 'test-api-key';
    process.env.OPENAI_MODEL = 'gpt-4o-mini';
    process.env.OPENAI_TIMEOUT = '30000';
    process.env.OPENAI_MAX_TOKENS = '600';

    // Mock database
    mockSQL = jest.fn();
    const { getDatabase } = require('../database/connection.js');
    getDatabase.mockReturnValue({
      getSQL: () => mockSQL
    });

    // Mock OpenAI constructor and methods
    (OpenAI as jest.MockedClass<typeof OpenAI>).mockImplementation(() => mockOpenAI as any);

    instagramAIService = new InstagramAIService();
  });

  afterEach(() => {
    delete process.env.OPENAI_API_KEY;
  });

  describe('Constructor', () => {
    test('âœ… should initialize with API key', () => {
      expect(OpenAI).toHaveBeenCalledWith({
        apiKey: 'test-api-key',
        timeout: 30000
      });
    });
  });

  describe('generateInstagramResponse', () => {
    const mockInstagramResponse: InstagramAIResponse = {
      message: 'Ø£Ù‡Ù„Ø§Ù‹ Ø­Ø¨ÙŠØ¨ØªÙŠ! ðŸ’• Ø­Ø¨ÙŠØªÙŠ Ø§Ù„Ø³ØªÙˆØ±ÙŠØŸ Ø¹Ù†Ø¯Ù†Ø§ Ù…ÙˆØ¯ÙŠÙ„Ø§Øª Ø¬Ø¯ÙŠØ¯Ø© Ø­ØµØ±ÙŠØ© ðŸ”¥âœ¨',
      messageAr: 'Ø£Ù‡Ù„Ø§Ù‹ Ø­Ø¨ÙŠØ¨ØªÙŠ! ðŸ’• Ø­Ø¨ÙŠØªÙŠ Ø§Ù„Ø³ØªÙˆØ±ÙŠØŸ Ø¹Ù†Ø¯Ù†Ø§ Ù…ÙˆØ¯ÙŠÙ„Ø§Øª Ø¬Ø¯ÙŠØ¯Ø© Ø­ØµØ±ÙŠØ© ðŸ”¥âœ¨',
      intent: 'PRODUCT_INQUIRY',
      stage: 'PRODUCT_SELECTION',
      actions: [
        { type: 'SHOW_PRODUCT', data: { category: 'fashion' }, priority: 1 }
      ],
      products: [
        {
          productId: 'dress-1',
          sku: 'DR001',
          name: 'ÙØ³ØªØ§Ù† Ø³Ù‡Ø±Ø©',
          price: 150,
          confidence: 0.9,
          reason: 'Ù…ÙˆØ¯ÙŠÙ„ ØªØ±Ù†Ø¯ÙŠ ÙˆÙ…Ù†Ø§Ø³Ø¨ Ù„Ù„Ø³Ù‡Ø±Ø§Øª'
        }
      ],
      confidence: 0.9,
      tokens: { prompt: 0, completion: 0, total: 0 },
      responseTime: 0,
      visualStyle: 'story',
      engagement: {
        likelyToShare: true,
        viralPotential: 0.8,
        userGeneratedContent: true
      },
      mediaRecommendations: [
        {
          type: 'story',
          content: 'ØµÙˆØ±Ø© Ù„Ù„ÙØ³ØªØ§Ù† Ù…Ø¹ Ø¥Ø¶Ø§Ø¡Ø© Ù†Ø§Ø¹Ù…Ø©',
          caption: 'ÙØ³Ø§ØªÙŠÙ† Ø³Ù‡Ø±Ø© Ø¬Ø¯ÙŠØ¯Ø© ðŸ’ƒâœ¨',
          hashtags: ['#ÙØ³Ø§ØªÙŠÙ†', '#Ø³Ù‡Ø±Ø©', '#Ù…ÙˆØ¶Ø©'],
          callToAction: 'Ø±Ø§Ø³Ù„ÙŠÙ†ÙŠ Ù„Ù„Ø·Ù„Ø¨ ðŸ“±'
        }
      ],
      hashtagSuggestions: ['#Ø¹Ø±Ø§Ù‚', '#Ù…ÙˆØ¶Ø©', '#ØªØ±Ù†Ø¯']
    };

    beforeEach(() => {
      // Mock merchant config query
      mockSQL.mockResolvedValueOnce([
        {
          ai_config: {
            model: 'gpt-4o-mini',
            maxTokens: 600,
            temperature: 0.8,
            language: 'ar'
          }
        }
      ]);

      // Mock OpenAI response
      mockOpenAI.chat.completions.create.mockResolvedValue({
        choices: [{
          message: {
            content: JSON.stringify(mockInstagramResponse)
          }
        }],
        usage: {
          prompt_tokens: 200,
          completion_tokens: 150,
          total_tokens: 350
        }
      });

      // Mock additional database calls for logging
      mockSQL.mockResolvedValue([]);
    });

    test('âœ… should generate Instagram-optimized response', async () => {
      const response = await instagramAIService.generateInstagramResponse(
        'Ø­Ø¨ÙŠØª Ø§Ù„Ø³ØªÙˆØ±ÙŠ! ÙˆÙŠÙ† Ø£ÙƒØ¯Ø± Ø£Ø´ØªØ±ÙŠ Ù‡Ø°Ø§ Ø§Ù„ÙØ³ØªØ§Ù†ØŸ',
        sampleInstagramContext
      );

      expect(response).toMatchObject({
        message: expect.stringContaining('ðŸ’•'),
        intent: 'PRODUCT_INQUIRY',
        visualStyle: 'story',
        engagement: {
          likelyToShare: true,
          viralPotential: expect.any(Number),
          userGeneratedContent: true
        }
      });

      expect(response.tokens).toEqual({
        prompt: 200,
        completion: 150,
        total: 350
      });

      expect(response.hashtagSuggestions).toContain('#Ø¹Ø±Ø§Ù‚');
    });

    test('âœ… should load merchant-specific AI configuration', async () => {
      await instagramAIService.generateInstagramResponse(
        'test message',
        sampleInstagramContext
      );

      expect(mockSQL).toHaveBeenCalledWith(
        expect.arrayContaining(['merchant-123'])
      );

      expect(mockOpenAI.chat.completions.create).toHaveBeenCalledWith({
        model: 'gpt-4o-mini',
        messages: expect.any(Array),
        temperature: 0.8,
        max_tokens: 600,
        top_p: 0.95,
        frequency_penalty: 0.2,
        presence_penalty: 0.3,
        response_format: { type: 'json_object' }
      });
    });

    test('âœ… should use default config when merchant config unavailable', async () => {
      mockSQL.mockResolvedValueOnce([]); // No merchant config

      await instagramAIService.generateInstagramResponse(
        'test message',
        sampleInstagramContext
      );

      expect(mockOpenAI.chat.completions.create).toHaveBeenCalledWith(
        expect.objectContaining({
          model: 'gpt-4o-mini',
          temperature: 0.8,
          max_tokens: 600
        })
      );
    });

    test('âœ… should include Instagram-specific context in prompt', async () => {
      await instagramAIService.generateInstagramResponse(
        'Ø£Ø±ÙŠØ¯ Ù‡Ø°Ø§ Ø§Ù„Ù…Ù†ØªØ¬',
        sampleInstagramContext
      );

      const callArgs = mockOpenAI.chat.completions.create.mock.calls[0][0];
      const systemMessage = callArgs.messages[0];
      
      expect(systemMessage.content).toContain('Instagram');
      expect(systemMessage.content).toContain('story_reply');
      expect(systemMessage.content).toContain('Ø¨ÙˆØªÙŠÙƒ Ø§Ù„Ø¹ØµØ±ÙŠØ©');
      expect(systemMessage.content).toContain('Ø±Ù…ÙˆØ² ØªØ¹Ø¨ÙŠØ±ÙŠØ©');
    });

    test('âœ… should add interaction type context to user message', async () => {
      await instagramAIService.generateInstagramResponse(
        'Ù…Ø±Ø­Ø¨Ø§',
        sampleInstagramContext
      );

      const callArgs = mockOpenAI.chat.completions.create.mock.calls[0][0];
      const userMessage = callArgs.messages[callArgs.messages.length - 1];
      
      expect(userMessage.content).toContain('[Ø±Ø¯Ù‘ Ø¹Ù„Ù‰ Ø³ØªÙˆØ±ÙŠ]');
      expect(userMessage.content).toContain('Ù…Ø±Ø­Ø¨Ø§');
    });

    test('âŒ should return contextual fallback on OpenAI error', async () => {
      mockOpenAI.chat.completions.create.mockRejectedValue(new Error('API Error'));

      const response = await instagramAIService.generateInstagramResponse(
        'test message',
        sampleInstagramContext
      );

      expect(response.intent).toBe('SUPPORT');
      expect(response.actions[0].type).toBe('ESCALATE');
      expect(response.message).toContain('Ø´ÙƒØ±Ø§Ù‹ Ù„ØªÙØ§Ø¹Ù„Ùƒ Ù…Ø¹ Ø³ØªÙˆØ±ÙŠÙ†Ø§');
      expect(response.visualStyle).toBe('story');
    });

    test('âŒ should handle invalid JSON response', async () => {
      mockOpenAI.chat.completions.create.mockResolvedValue({
        choices: [{ message: { content: 'invalid json' } }],
        usage: { prompt_tokens: 0, completion_tokens: 0, total_tokens: 0 }
      });

      const response = await instagramAIService.generateInstagramResponse(
        'test',
        sampleInstagramContext
      );

      expect(response.intent).toBe('SUPPORT');
      expect(response.message).toContain('Ø³ØªÙˆØ±ÙŠÙ†Ø§');
    });

    test('âŒ should handle missing required fields in AI response', async () => {
      const incompleteResponse = {
        message: 'test message'
        // Missing messageAr, intent, actions
      };

      mockOpenAI.chat.completions.create.mockResolvedValue({
        choices: [{ message: { content: JSON.stringify(incompleteResponse) } }],
        usage: { prompt_tokens: 0, completion_tokens: 0, total_tokens: 0 }
      });

      const response = await instagramAIService.generateInstagramResponse(
        'test',
        sampleInstagramContext
      );

      expect(response.intent).toBe('SUPPORT');
    });

    test('âœ… should handle different interaction types', async () => {
      const commentContext = {
        ...sampleInstagramContext,
        interactionType: 'comment' as const
      };

      await instagramAIService.generateInstagramResponse(
        'Ù…Ù†ØªØ¬ Ø­Ù„Ùˆ',
        commentContext
      );

      const callArgs = mockOpenAI.chat.completions.create.mock.calls[0][0];
      const userMessage = callArgs.messages[callArgs.messages.length - 1];
      
      expect(userMessage.content).toContain('[ØªØ¹Ù„ÙŠÙ‚ Ø¹Ù„Ù‰ Ù…Ù†Ø´ÙˆØ±]');
    });
  });

  describe('generateStoryReply', () => {
    const storyContext = {
      mediaId: 'story-456',
      mediaType: 'video',
      caption: 'Ù…Ø¬Ù…ÙˆØ¹ØªÙ†Ø§ Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø© ðŸ”¥'
    };

    const mockStoryResponse = {
      message: 'ÙŠØ§ Ø³Ù„Ø§Ù… Ø¹Ù„Ù‰ Ø§Ù„Ø°ÙˆÙ‚! ðŸ˜ðŸ”¥ Ø±Ø§Ø³Ù„ÙŠÙ†ÙŠ Ù„Ù„Ø·Ù„Ø¨ Ø­Ø¨ÙŠØ¨ØªÙŠ',
      messageAr: 'ÙŠØ§ Ø³Ù„Ø§Ù… Ø¹Ù„Ù‰ Ø§Ù„Ø°ÙˆÙ‚! ðŸ˜ðŸ”¥ Ø±Ø§Ø³Ù„ÙŠÙ†ÙŠ Ù„Ù„Ø·Ù„Ø¨ Ø­Ø¨ÙŠØ¨ØªÙŠ',
      intent: 'ENGAGEMENT',
      stage: 'INITIAL_CONTACT',
      actions: [{ type: 'COLLECT_INFO', data: {}, priority: 1 }],
      products: [],
      confidence: 0.9
    };

    beforeEach(() => {
      mockOpenAI.chat.completions.create.mockResolvedValue({
        choices: [{ message: { content: JSON.stringify(mockStoryResponse) } }]
      });
    });

    test('âœ… should generate story reply response', async () => {
      const response = await instagramAIService.generateStoryReply(
        'Ø­Ù„Ùˆ ÙƒØ«ÙŠØ±! ðŸ˜',
        storyContext,
        sampleInstagramContext
      );

      expect(response.visualStyle).toBe('story');
      expect(response.engagement.likelyToShare).toBe(true);
      expect(response.engagement.viralPotential).toBe(0.7);
      expect(response.engagement.userGeneratedContent).toBe(true);
    });

    test('âœ… should use high temperature for creativity', async () => {
      await instagramAIService.generateStoryReply(
        'Ø±Ø§Ø¦Ø¹',
        storyContext,
        sampleInstagramContext
      );

      expect(mockOpenAI.chat.completions.create).toHaveBeenCalledWith({
        model: 'gpt-4o-mini',
        messages: expect.any(Array),
        temperature: 0.9,
        max_tokens: 200,
        response_format: { type: 'json_object' }
      });
    });

    test('âœ… should include story context in prompt', async () => {
      await instagramAIService.generateStoryReply(
        'Ø£Ø¹Ø¬Ø¨Ù†ÙŠ',
        storyContext,
        sampleInstagramContext
      );

      const callArgs = mockOpenAI.chat.completions.create.mock.calls[0][0];
      const systemMessage = callArgs.messages[0];
      
      expect(systemMessage.content).toContain('video');
      expect(systemMessage.content).toContain('Ù…Ø¬Ù…ÙˆØ¹ØªÙ†Ø§ Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø© ðŸ”¥');
    });

    test('âŒ should return fallback on error', async () => {
      mockOpenAI.chat.completions.create.mockRejectedValue(new Error('API Error'));

      const response = await instagramAIService.generateStoryReply(
        'test',
        storyContext,
        sampleInstagramContext
      );

      expect(response.intent).toBe('SUPPORT');
      expect(response.message).toContain('ðŸ™');
    });
  });

  describe('generateCommentResponse', () => {
    const postContext = {
      mediaId: 'post-789',
      caption: 'Ù…Ù†ØªØ¬Ø§ØªÙ†Ø§ Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø© Ù…ØªÙˆÙØ±Ø© Ø§Ù„Ø¢Ù†'
    };

    const mockCommentResponse = {
      message: 'Ø´ÙƒØ±Ø§Ù‹ Ù„ØªØ¹Ù„ÙŠÙ‚Ùƒ Ø§Ù„Ø¬Ù…ÙŠÙ„! ðŸ’™ Ø±Ø§Ø³Ù„ÙŠÙ†Ø§ Ø®Ø§Øµ Ù„Ù„ØªÙØ§ØµÙŠÙ„',
      messageAr: 'Ø´ÙƒØ±Ø§Ù‹ Ù„ØªØ¹Ù„ÙŠÙ‚Ùƒ Ø§Ù„Ø¬Ù…ÙŠÙ„! ðŸ’™ Ø±Ø§Ø³Ù„ÙŠÙ†Ø§ Ø®Ø§Øµ Ù„Ù„ØªÙØ§ØµÙŠÙ„',
      intent: 'CUSTOMER_SERVICE',
      stage: 'INITIAL_CONTACT',
      actions: [{ type: 'COLLECT_INFO', data: {}, priority: 1 }],
      products: [],
      confidence: 0.8
    };

    beforeEach(() => {
      mockOpenAI.chat.completions.create.mockResolvedValue({
        choices: [{ message: { content: JSON.stringify(mockCommentResponse) } }]
      });
    });

    test('âœ… should generate comment response', async () => {
      const response = await instagramAIService.generateCommentResponse(
        'Ù‡Ù„ Ù…ØªÙˆÙØ± Ø¨Ø§Ù„Ø£Ø²Ø±Ù‚ØŸ',
        postContext,
        sampleInstagramContext
      );

      expect(response.visualStyle).toBe('post');
      expect(response.engagement.likelyToShare).toBe(false);
      expect(response.engagement.viralPotential).toBe(0.4);
      expect(response.engagement.userGeneratedContent).toBe(false);
    });

    test('âœ… should use moderate temperature for comments', async () => {
      await instagramAIService.generateCommentResponse(
        'Ø³Ø¤Ø§Ù„',
        postContext,
        sampleInstagramContext
      );

      expect(mockOpenAI.chat.completions.create).toHaveBeenCalledWith({
        model: 'gpt-4o-mini',
        messages: expect.any(Array),
        temperature: 0.7,
        max_tokens: 150,
        response_format: { type: 'json_object' }
      });
    });

    test('âŒ should return fallback on error', async () => {
      mockOpenAI.chat.completions.create.mockRejectedValue(new Error('API Error'));

      const response = await instagramAIService.generateCommentResponse(
        'test',
        postContext,
        sampleInstagramContext
      );

      expect(response.intent).toBe('SUPPORT');
      expect(response.message).toContain('ðŸ’™');
    });
  });

  describe('generateProductShowcase', () => {
    const mockProducts = [
      {
        id: 'prod-1',
        sku: 'DR001',
        name_ar: 'ÙØ³ØªØ§Ù† Ø³Ù‡Ø±Ø©',
        price_usd: 150,
        category: 'fashion',
        description_ar: 'ÙØ³ØªØ§Ù† Ø£Ù†ÙŠÙ‚ Ù„Ù„Ø³Ù‡Ø±Ø§Øª',
        image_urls: ['image1.jpg']
      }
    ];

    const mockShowcase = {
      mediaRecommendations: [
        {
          type: 'carousel',
          content: 'ØµÙˆØ± Ù…ØªØ¹Ø¯Ø¯Ø© Ù„Ù„ÙØ³ØªØ§Ù†',
          caption: 'ÙØ³Ø§ØªÙŠÙ† Ø³Ù‡Ø±Ø© Ø¬Ø¯ÙŠØ¯Ø© ðŸ’ƒâœ¨',
          hashtags: ['#ÙØ³Ø§ØªÙŠÙ†', '#Ø³Ù‡Ø±Ø©'],
          callToAction: 'Ø±Ø§Ø³Ù„ÙŠÙ†ÙŠ Ù„Ù„Ø·Ù„Ø¨'
        }
      ],
      caption: 'Ù…Ø¬Ù…ÙˆØ¹Ø© ÙØ³Ø§ØªÙŠÙ† Ø§Ù„Ø³Ù‡Ø±Ø© Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø© âœ¨',
      hashtags: ['#ÙØ³Ø§ØªÙŠÙ†', '#Ù…ÙˆØ¶Ø©', '#Ø¹Ø±Ø§Ù‚'],
      engagementBoosts: ['Ø§Ø³ØªØ®Ø¯Ù… Ø±Ù…ÙˆØ² ØªØ¹Ø¨ÙŠØ±ÙŠØ©', 'Ø§Ø·Ø±Ø­ Ø³Ø¤Ø§Ù„ Ù„Ù„Ù…ØªØ§Ø¨Ø¹ÙŠÙ†']
    };

    beforeEach(() => {
      // Mock products query
      mockSQL.mockResolvedValue(mockProducts);

      // Mock OpenAI response
      mockOpenAI.chat.completions.create.mockResolvedValue({
        choices: [{ message: { content: JSON.stringify(mockShowcase) } }]
      });
    });

    test('âœ… should generate product showcase', async () => {
      const showcase = await instagramAIService.generateProductShowcase(
        ['prod-1'],
        sampleInstagramContext
      );

      expect(showcase.mediaRecommendations).toHaveLength(1);
      expect(showcase.caption).toContain('ÙØ³Ø§ØªÙŠÙ†');
      expect(showcase.hashtags).toContain('#ÙØ³Ø§ØªÙŠÙ†');
      expect(showcase.engagementBoosts).toBeDefined();
    });

    test('âœ… should fetch products for showcase', async () => {
      await instagramAIService.generateProductShowcase(
        ['prod-1', 'prod-2'],
        sampleInstagramContext
      );

      expect(mockSQL).toHaveBeenCalledWith(
        expect.arrayContaining(['merchant-123'])
      );
    });

    test('âœ… should handle large product batches', async () => {
      const manyProductIds = Array.from({ length: 100 }, (_, i) => `prod-${i}`);

      await instagramAIService.generateProductShowcase(
        manyProductIds,
        sampleInstagramContext
      );

      // Should batch requests (50 per batch = 2 batches)
      expect(mockSQL).toHaveBeenCalledTimes(2);
    });

    test('âŒ should return empty showcase on error', async () => {
      mockOpenAI.chat.completions.create.mockRejectedValue(new Error('API Error'));

      const showcase = await instagramAIService.generateProductShowcase(
        ['prod-1'],
        sampleInstagramContext
      );

      expect(showcase).toEqual({
        mediaRecommendations: [],
        caption: '',
        hashtags: [],
        engagementBoosts: []
      });
    });
  });

  describe('analyzeContentPerformance', () => {
    const mockAnalysis = {
      viralScore: 8,
      engagementPrediction: 7,
      audienceMatch: 9,
      optimizationSuggestions: [
        'Ø£Ø¶Ù Ø§Ù„Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„Ø±Ù…ÙˆØ² Ø§Ù„ØªØ¹Ø¨ÙŠØ±ÙŠØ©',
        'Ø§Ø³ØªØ®Ø¯Ù… Ù‡Ø§Ø´ØªØ§Ø¬Ø§Øª ØªØ±Ù†Ø¯ÙŠØ© Ø£ÙƒØ«Ø±'
      ]
    };

    beforeEach(() => {
      mockOpenAI.chat.completions.create.mockResolvedValue({
        choices: [{ message: { content: JSON.stringify(mockAnalysis) } }]
      });
    });

    test('âœ… should analyze content performance', async () => {
      const analysis = await instagramAIService.analyzeContentPerformance(
        'ÙØ³Ø§ØªÙŠÙ† Ø¬Ø¯ÙŠØ¯Ø© ðŸ”¥ #Ù…ÙˆØ¶Ø© #Ø¹Ø±Ø§Ù‚',
        'post',
        sampleInstagramContext
      );

      expect(analysis.viralScore).toBe(8);
      expect(analysis.engagementPrediction).toBe(7);
      expect(analysis.audienceMatch).toBe(9);
      expect(analysis.optimizationSuggestions).toHaveLength(2);
    });

    test('âœ… should use appropriate parameters for analysis', async () => {
      await instagramAIService.analyzeContentPerformance(
        'test content',
        'reel',
        sampleInstagramContext
      );

      expect(mockOpenAI.chat.completions.create).toHaveBeenCalledWith({
        model: 'gpt-4o-mini',
        messages: expect.any(Array),
        temperature: 0.4,
        max_tokens: 400,
        response_format: { type: 'json_object' }
      });
    });

    test('âŒ should return zero scores on error', async () => {
      mockOpenAI.chat.completions.create.mockRejectedValue(new Error('API Error'));

      const analysis = await instagramAIService.analyzeContentPerformance(
        'test',
        'story',
        sampleInstagramContext
      );

      expect(analysis).toEqual({
        viralScore: 0,
        engagementPrediction: 0,
        audienceMatch: 0,
        optimizationSuggestions: []
      });
    });
  });

  describe('Hashtag Generation', () => {
    test('âœ… should generate relevant hashtags', async () => {
      const hashtags = await (instagramAIService as any).generateRelevantHashtags(
        'Ø£Ø±ÙŠØ¯ ÙØ³ØªØ§Ù† Ù„Ù„Ø²ÙØ§Ù',
        sampleInstagramContext
      );

      expect(hashtags).toContain('#Ø¹Ø±Ø§Ù‚');
      expect(hashtags).toContain('#Ù…ÙˆØ¶Ø©');
      expect(hashtags).toContain('#ØªØ±Ù†Ø¯');
      expect(hashtags.length).toBeLessThanOrEqual(8);
    });

    test('âœ… should include category-specific hashtags', async () => {
      const electronicsContext = {
        ...sampleInstagramContext,
        merchantSettings: {
          ...sampleInstagramContext.merchantSettings!,
          businessCategory: 'electronics'
        }
      };

      const hashtags = await (instagramAIService as any).generateRelevantHashtags(
        'Ø£Ø±ÙŠØ¯ Ø¬ÙˆØ§Ù„ Ø¬Ø¯ÙŠØ¯',
        electronicsContext
      );

      expect(hashtags).toContain('#Ø¬ÙˆØ§Ù„Ø§Øª');
      expect(hashtags).toContain('#ØªÙƒÙ†ÙˆÙ„ÙˆØ¬ÙŠØ§');
    });

    test('âŒ should return fallback hashtags on error', async () => {
      // Force error by passing invalid context
      const hashtags = await (instagramAIService as any).generateRelevantHashtags(
        'test',
        null
      );

      expect(hashtags).toEqual(['#Ø¹Ø±Ø§Ù‚', '#ØªØ³ÙˆÙ‚', '#Ø¬Ø¯ÙŠØ¯']);
    });
  });

  describe('Contextual Fallbacks', () => {
    test('âœ… should provide different fallbacks by interaction type', () => {
      const storyReplyFallback = (instagramAIService as any).getContextualFallback(
        { ...sampleInstagramContext, interactionType: 'story_reply' },
        'AI_API_ERROR'
      );

      const dmFallback = (instagramAIService as any).getContextualFallback(
        { ...sampleInstagramContext, interactionType: 'dm' },
        'AI_API_ERROR'
      );

      expect(storyReplyFallback.message).toContain('Ø³ØªÙˆØ±ÙŠÙ†Ø§');
      expect(dmFallback.message).toContain('Ø§Ù„Ù†Ø¸Ø§Ù… Ù…Ø´ØºÙˆÙ„');
    });

    test('âœ… should handle different error types', () => {
      const rateLimitFallback = (instagramAIService as any).getContextualFallback(
        sampleInstagramContext,
        'RATE_LIMIT'
      );

      const networkErrorFallback = (instagramAIService as any).getContextualFallback(
        sampleInstagramContext,
        'NETWORK_ERROR'
      );

      expect(rateLimitFallback.message).toContain('Ù‚Ø±ÙŠØ¨Ø§Ù‹');
      expect(networkErrorFallback.message).toContain('Ø®Ø§Øµ');
    });

    test('âœ… should set appropriate engagement values for fallbacks', () => {
      const storyFallback = (instagramAIService as any).getContextualFallback(
        { ...sampleInstagramContext, interactionType: 'story_reply' },
        'AI_API_ERROR'
      );

      const dmFallback = (instagramAIService as any).getContextualFallback(
        { ...sampleInstagramContext, interactionType: 'dm' },
        'AI_API_ERROR'
      );

      expect(storyFallback.engagement.likelyToShare).toBe(true);
      expect(storyFallback.engagement.viralPotential).toBe(0.7);
      expect(dmFallback.engagement.likelyToShare).toBe(false);
    });
  });

  describe('Logging and Analytics', () => {
    beforeEach(() => {
      // Setup successful response
      mockSQL.mockResolvedValueOnce([{ ai_config: null }]); // Config query
      mockSQL.mockResolvedValue([]); // All other queries

      mockOpenAI.chat.completions.create.mockResolvedValue({
        choices: [{
          message: {
            content: JSON.stringify({
              message: 'test',
              messageAr: 'test',
              intent: 'TEST',
              stage: 'TEST',
              actions: [],
              products: [],
              confidence: 0.8
            })
          }
        }],
        usage: { prompt_tokens: 100, completion_tokens: 50, total_tokens: 150 }
      });
    });

    test('âœ… should log Instagram AI interactions', async () => {
      await instagramAIService.generateInstagramResponse(
        'test message',
        sampleInstagramContext
      );

      // Should call audit_logs insert
      expect(mockSQL).toHaveBeenCalledWith(
        expect.arrayContaining([
          'merchant-123',
          'INSTAGRAM_AI_RESPONSE_GENERATED',
          'AI_INTERACTION'
        ])
      );

      // Should call instagram_analytics insert
      expect(mockSQL).toHaveBeenCalledWith(
        expect.arrayContaining([
          'merchant-123',
          'story_reply',
          150 // total tokens
        ])
      );
    });

    test('âœ… should handle logging errors gracefully', async () => {
      const consoleSpy = jest.spyOn(console, 'error').mockImplementation();
      
      // Make logging fail
      mockSQL.mockImplementation((sql) => {
        if (sql.toString().includes('audit_logs')) {
          return Promise.reject(new Error('DB Error'));
        }
        return Promise.resolve([]);
      });

      const response = await instagramAIService.generateInstagramResponse(
        'test',
        sampleInstagramContext
      );

      expect(response).toBeDefined();
      
      consoleSpy.mockRestore();
    });
  });

  describe('Performance Optimization', () => {
    test('âœ… should batch database operations', async () => {
      const operations = [
        () => Promise.resolve('result1'),
        () => Promise.resolve('result2'),
        () => Promise.resolve('result3')
      ];

      const results = await (instagramAIService as any).processCommentBatch(operations);

      expect(results).toEqual(['result1', 'result2', 'result3']);
    });

    test('âŒ should handle batch operation failures', async () => {
      const operations = [
        () => Promise.resolve('success'),
        () => Promise.reject(new Error('failure')),
        () => Promise.resolve('success2')
      ];

      const results = await (instagramAIService as any).processCommentBatch(operations);

      expect(results).toEqual([]);
    });

    test('âœ… should handle large product batches efficiently', async () => {
      const manyProducts = Array.from({ length: 150 }, (_, i) => ({
        id: `prod-${i}`,
        sku: `SKU${i}`,
        name_ar: `Ù…Ù†ØªØ¬ ${i}`,
        price_usd: 100,
        category: 'test'
      }));

      mockSQL.mockResolvedValue(manyProducts.slice(0, 50)); // Simulate batch response

      const productIds = manyProducts.map(p => p.id);
      const results = await (instagramAIService as any).getProductsForShowcase(
        productIds,
        'merchant-123'
      );

      // Should make 3 batch calls (150 products / 50 per batch)
      expect(mockSQL).toHaveBeenCalledTimes(3);
      expect(results.length).toBeGreaterThan(0);
    });
  });

  describe('Singleton Pattern', () => {
    test('âœ… should return same instance', () => {
      const instance1 = getInstagramAIService();
      const instance2 = getInstagramAIService();

      expect(instance1).toBe(instance2);
    });

    test('âœ… should create instance if not exists', () => {
      // Reset singleton
      (require('./instagram-ai.js') as any).instagramAIServiceInstance = null;

      const instance = getInstagramAIService();
      expect(instance).toBeInstanceOf(InstagramAIService);
    });
  });

  describe('Edge Cases', () => {
    test('âœ… should handle unknown interaction type', () => {
      const unknownContext = {
        ...sampleInstagramContext,
        interactionType: 'unknown_type' as any
      };

      const fallback = (instagramAIService as any).getContextualFallback(
        unknownContext,
        'AI_API_ERROR'
      );

      // Should default to 'dm' behavior
      expect(fallback.message).toContain('Ø§Ù„Ù†Ø¸Ø§Ù… Ù…Ø´ØºÙˆÙ„');
    });

    test('âœ… should handle missing media context', async () => {
      const contextWithoutMedia = {
        ...sampleInstagramContext,
        mediaContext: undefined
      };

      await instagramAIService.generateInstagramResponse(
        'test',
        contextWithoutMedia
      );

      const callArgs = mockOpenAI.chat.completions.create.mock.calls[0][0];
      const systemMessage = callArgs.messages[0];
      
      expect(systemMessage.content).toContain('Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ù…Ø­ØªÙˆÙ‰ Ø¨ØµØ±ÙŠ');
    });

    test('âœ… should handle missing merchant settings', async () => {
      const contextWithoutSettings = {
        ...sampleInstagramContext,
        merchantSettings: undefined
      };

      await instagramAIService.generateInstagramResponse(
        'test',
        contextWithoutSettings
      );

      const callArgs = mockOpenAI.chat.completions.create.mock.calls[0][0];
      const systemMessage = callArgs.messages[0];
      
      expect(systemMessage.content).toContain('ØºÙŠØ± Ù…Ø­Ø¯Ø¯');
    });

    test('âœ… should handle empty product showcase', async () => {
      mockSQL.mockResolvedValue([]); // No products found

      const showcase = await instagramAIService.generateProductShowcase(
        ['nonexistent-product'],
        sampleInstagramContext
      );

      expect(showcase.mediaRecommendations).toEqual([]);
    });
  });
});