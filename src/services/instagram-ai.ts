/**
 * ===============================================
 * Instagram AI Service - STEP 3 Implementation
 * AI conversation adaptation for Instagram's visual, casual, emoji-rich style
 * ===============================================
 */

import { AIService, type ConversationContext, type AIResponse, type MessageHistory } from './ai.js';
import { getDatabase } from '../database/connection.js';
import OpenAI from 'openai';

// Simple merchant configuration interface
interface MerchantAIConfig {
  aiModel: string;
  maxTokens: number;
  temperature: number;
  language: string;
}

export interface InstagramAIResponse extends AIResponse {
  mediaRecommendations?: MediaRecommendation[];
  hashtagSuggestions?: string[];
  visualStyle: 'story' | 'post' | 'reel' | 'direct';
  engagement: {
    likelyToShare: boolean;
    viralPotential: number;
    userGeneratedContent: boolean;
  };
}

export interface MediaRecommendation {
  type: 'image' | 'video' | 'carousel' | 'story';
  content: string;
  caption: string;
  hashtags: string[];
  callToAction: string;
}

type ErrorCode = 'AI_API_ERROR' | 'RATE_LIMIT' | 'NETWORK_ERROR';

export interface InstagramContext extends ConversationContext {
  interactionType: 'dm' | 'comment' | 'story_reply' | 'story_mention';
  mediaContext?: {
    mediaId?: string;
    mediaType?: 'video' | 'carousel' | 'photo';
    caption?: string;
    hashtags?: string[];
    [k: string]: any;
  };
  visualPreferences?: {
    colorScheme: string[];
    aestheticStyle: string;
    contentType: string[];
  };
}

export class InstagramAIService extends AIService {
  /**
   * Get merchant-specific AI configuration
   */
  private async getConfigForMerchant(merchantId: string): Promise<MerchantAIConfig> {
    try {
      const sql = this.db.getSQL();
      const result = await sql`
        SELECT ai_config 
        FROM merchants 
        WHERE id = ${merchantId}::uuid
      `;
      
      if (result.length > 0 && result[0].ai_config) {
        return {
          aiModel: result[0].ai_config.model || 'gpt-4o-mini',
          maxTokens: result[0].ai_config.maxTokens || 600,
          temperature: result[0].ai_config.temperature || 0.8,
          language: result[0].ai_config.language || 'ar'
        };
      }
      
      // Default configuration
      return {
        aiModel: process.env.OPENAI_MODEL || 'gpt-4o-mini',
        maxTokens: parseInt(process.env.OPENAI_MAX_TOKENS || '600'),
        temperature: 0.8,
        language: 'ar'
      };
    } catch (error) {
      console.error('âŒ Error loading merchant config:', error);
      return {
        aiModel: 'gpt-4o-mini',
        maxTokens: 600,
        temperature: 0.8,
        language: 'ar'
      };
    }
  }

  /**
   * Get contextual fallback based on interaction type and error
   */
  private getContextualFallback(context: InstagramContext, errorType: string): InstagramAIResponse {
    const fallbacks = {
      'story_reply': {
        'AI_API_ERROR': 'Ø´ÙƒØ±Ø§Ù‹ Ù„ØªÙØ§Ø¹Ù„Ùƒ Ù…Ø¹ Ø³ØªÙˆØ±ÙŠÙ†Ø§! ğŸ“±âœ¨ Ø±Ø§Ø³Ù„Ù†Ø§ Ù„Ù„Ù…Ø²ÙŠØ¯',
        'RATE_LIMIT': 'Ø³ØªÙˆØ±ÙŠÙ†Ø§ Ø±Ø§Ø¦Ø¹Ø©! ğŸ”¥ Ø±Ø§Ø­ Ù†Ø±Ø¯ Ø¹Ù„ÙŠÙƒ Ù‚Ø±ÙŠØ¨Ø§Ù‹',
        'NETWORK_ERROR': 'Ø´ÙØª Ø³ØªÙˆØ±ÙŠÙ†Ø§! ğŸ’• Ø±Ø§Ø³Ù„Ù†Ø§ Ø®Ø§Øµ Ù„Ù„Ù…Ø²ÙŠØ¯'
      },
      'comment': {
        'AI_API_ERROR': 'Ø´ÙƒØ±Ø§Ù‹ Ù„ØªØ¹Ù„ÙŠÙ‚Ùƒ! ğŸ’™ Ø±Ø§Ø³Ù„Ù†Ø§ Ø®Ø§Øµ Ù„Ù„Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„ØªÙØ§ØµÙŠÙ„',
        'RATE_LIMIT': 'Ø´ÙƒØ±Ø§Ù‹ Ù„ØªÙØ§Ø¹Ù„Ùƒ! Ø±Ø§Ø­ Ù†Ø±Ø¯ Ø¹Ù„ÙŠÙƒ Ù‚Ø±ÙŠØ¨Ø§Ù‹ ğŸŒ¹',
        'NETWORK_ERROR': 'Ø´ÙƒØ±Ø§Ù‹ Ù„ØªØ¹Ù„ÙŠÙ‚Ùƒ Ø§Ù„Ø¬Ù…ÙŠÙ„! Ø±Ø§Ø³Ù„Ù†Ø§ Ø®Ø§Øµ âœ¨'
      },
      'dm': {
        'AI_API_ERROR': 'Ø¹Ø°Ø±Ø§Ù‹ Ù„Ù„Ø§Ù†ØªØ¸Ø§Ø±! Ø§Ù„Ù†Ø¸Ø§Ù… Ù…Ø´ØºÙˆÙ„ Ø­Ø§Ù„ÙŠØ§Ù‹. Ø±Ø§Ø­ Ø£Ø±Ø¯ Ø¹Ù„ÙŠÙƒ Ø®Ù„Ø§Ù„ Ø¯Ù‚Ø§Ø¦Ù‚ â°',
        'RATE_LIMIT': 'Ø´ÙƒØ±Ø§Ù‹ Ù„ØµØ¨Ø±Ùƒ! Ø±Ø§Ø­ Ø£Ø±Ø¯ Ø¹Ù„ÙŠÙƒ Ù‚Ø±ÙŠØ¨Ø§Ù‹ ğŸ™',
        'NETWORK_ERROR': 'Ø¹Ø°Ø±Ø§Ù‹ØŒ Ø­Ø¯Ø« Ø®Ø·Ø£ ØªÙ‚Ù†ÙŠ. Ø¬Ø§Ø±ÙŠ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù…Ø±Ø© Ø£Ø®Ø±Ù‰...'
      }
    };

    const contextType = context.interactionType === 'story_reply' ? 'story_reply' 
                       : context.interactionType === 'comment' ? 'comment' 
                       : 'dm';
    
    const fb = fallbacks[contextType as keyof typeof fallbacks] as Record<ErrorCode, string>;
    const code = (errorType as ErrorCode);
    const message = fb[code] ?? fb.AI_API_ERROR;

    return {
      message,
      messageAr: message,
      intent: 'SUPPORT',
      stage: context.stage,
      actions: [{ type: 'ESCALATE', data: { reason: errorType }, priority: 1 }],
      products: [],
      confidence: 0.1,
      tokens: { prompt: 0, completion: 0, total: 0 },
      responseTime: 0,
      visualStyle: contextType === 'story_reply' ? 'story' : 'direct',
      engagement: {
        likelyToShare: contextType === 'story_reply',
        viralPotential: contextType === 'story_reply' ? 0.7 : 0,
        userGeneratedContent: contextType === 'story_reply'
      },
      hashtagSuggestions: ['#Ù…Ø³Ø§Ø¹Ø¯Ø©']
    };
  }

  /**
   * Generate Instagram-optimized AI response
   */
  public async generateInstagramResponse(
    customerMessage: string,
    context: InstagramContext
  ): Promise<InstagramAIResponse> {
    const startTime = Date.now();

    try {
      // âœ… 1. Configuration Management: Get merchant-specific config
      const config = await this.getConfigForMerchant(context.merchantId);
      
      // Build Instagram-specific prompt
      const prompt = await this.buildInstagramConversationPrompt(customerMessage, context);
      
      const openai = new OpenAI({
        apiKey: process.env.OPENAI_API_KEY!,
        timeout: parseInt(process.env.OPENAI_TIMEOUT || '30000'),
      });

      // Call OpenAI with merchant-specific settings
      const completion = await openai.chat.completions.create({
        model: config.aiModel,
        messages: prompt,
        temperature: config.temperature,
        max_tokens: config.maxTokens,
        top_p: 0.95,
        frequency_penalty: 0.2,
        presence_penalty: 0.3,
        response_format: { type: 'json_object' }
      });

      const responseTime = Date.now() - startTime;
      const response = completion.choices[0]?.message?.content;

      if (!response) {
        throw new Error('No response from OpenAI for Instagram');
      }

      // Parse Instagram AI response
      const aiResponse = JSON.parse(response) as InstagramAIResponse;
      
      // Add metadata
      aiResponse.tokens = {
        prompt: completion.usage?.prompt_tokens || 0,
        completion: completion.usage?.completion_tokens || 0,
        total: completion.usage?.total_tokens || 0
      };
      aiResponse.responseTime = responseTime;

      // Enhance with Instagram-specific features
      aiResponse.hashtagSuggestions = await this.generateRelevantHashtags(
        customerMessage, 
        context
      );

      // Log Instagram AI interaction
      await this.logInstagramAIInteraction(context, customerMessage, aiResponse);

      return aiResponse;
    } catch (error) {
      console.error('âŒ Instagram AI response generation failed:', error);
      
      // âœ… 2. Error Handling: Use contextual fallback
      const errorType = error.message?.includes('rate limit') ? 'RATE_LIMIT'
                       : error.message?.includes('network') ? 'NETWORK_ERROR'
                       : 'AI_API_ERROR';
      
      return this.getContextualFallback(context, errorType);
    }
  }

  /**
   * Generate Instagram story reply response
   */
  public async generateStoryReply(
    storyReaction: string,
    storyContext: { mediaId: string; mediaType: string; caption?: string },
    context: InstagramContext
  ): Promise<InstagramAIResponse> {
    try {
      const prompt = this.buildStoryReplyPrompt(storyReaction, storyContext, context);

      const completion = await this.openai.chat.completions.create({
        model: process.env.OPENAI_MODEL || 'gpt-4o-mini',
        messages: prompt,
        temperature: 0.9, // Very creative for story interactions
        max_tokens: 200,
        response_format: { type: 'json_object' }
      });

      const response = completion.choices[0]?.message?.content;
      const aiResponse = JSON.parse(response || '{}') as InstagramAIResponse;

      // Set visual style for story replies
      aiResponse.visualStyle = 'story';
      aiResponse.engagement = {
        likelyToShare: true,
        viralPotential: 0.7,
        userGeneratedContent: true
      };

      return aiResponse;
    } catch (error) {
      console.error('âŒ Story reply generation failed:', error);
      return this.getInstagramFallbackResponse(context);
    }
  }

  /**
   * Generate comment response for Instagram posts
   */
  public async generateCommentResponse(
    commentText: string,
    postContext: { mediaId: string; caption?: string },
    context: InstagramContext
  ): Promise<InstagramAIResponse> {
    try {
      const prompt = this.buildCommentReplyPrompt(commentText, postContext, context);
      
      const openai = new OpenAI({
        apiKey: process.env.OPENAI_API_KEY!,
      });

      const completion = await openai.chat.completions.create({
        model: 'gpt-4o-mini',
        messages: prompt,
        temperature: 0.7,
        max_tokens: 150, // Comments should be concise
        response_format: { type: 'json_object' }
      });

      const response = completion.choices[0]?.message?.content;
      const aiResponse = JSON.parse(response || '{}') as InstagramAIResponse;

      // Set visual style for post comments
      aiResponse.visualStyle = 'post';
      aiResponse.engagement = {
        likelyToShare: false,
        viralPotential: 0.4,
        userGeneratedContent: false
      };

      return aiResponse;
    } catch (error) {
      console.error('âŒ Comment response generation failed:', error);
      return this.getInstagramFallbackResponse(context);
    }
  }

  /**
   * Generate Instagram-optimized product showcase
   */
  public async generateProductShowcase(
    productIds: string[],
    context: InstagramContext
  ): Promise<{
    mediaRecommendations: MediaRecommendation[];
    caption: string;
    hashtags: string[];
    engagementBoosts: string[];
  }> {
    try {
      const products = await this.getProductsForShowcase(productIds, context.merchantId);
      const prompt = this.buildProductShowcasePrompt(products, context);
      
      const openai = new OpenAI({
        apiKey: process.env.OPENAI_API_KEY!,
      });

      const completion = await openai.chat.completions.create({
        model: 'gpt-4o-mini',
        messages: prompt,
        temperature: 0.8,
        max_tokens: 800,
        response_format: { type: 'json_object' }
      });

      const response = completion.choices[0]?.message?.content;
      return JSON.parse(response || '{}');
    } catch (error) {
      console.error('âŒ Product showcase generation failed:', error);
      return {
        mediaRecommendations: [],
        caption: '',
        hashtags: [],
        engagementBoosts: []
      };
    }
  }

  /**
   * Analyze Instagram content performance potential
   */
  public async analyzeContentPerformance(
    content: string,
    contentType: 'story' | 'post' | 'reel',
    context: InstagramContext
  ): Promise<{
    viralScore: number;
    engagementPrediction: number;
    audienceMatch: number;
    optimizationSuggestions: string[];
  }> {
    try {
      const prompt = this.buildContentAnalysisPrompt(content, contentType, context);
      
      const openai = new OpenAI({
        apiKey: process.env.OPENAI_API_KEY!,
      });

      const completion = await openai.chat.completions.create({
        model: 'gpt-4o-mini',
        messages: prompt,
        temperature: 0.4,
        max_tokens: 400,
        response_format: { type: 'json_object' }
      });

      const response = completion.choices[0]?.message?.content;
      return JSON.parse(response || '{}');
    } catch (error) {
      console.error('âŒ Content performance analysis failed:', error);
      return {
        viralScore: 0,
        engagementPrediction: 0,
        audienceMatch: 0,
        optimizationSuggestions: []
      };
    }
  }

  /**
   * Private: Build Instagram-specific conversation prompt
   */
  private async buildInstagramConversationPrompt(
    customerMessage: string,
    context: InstagramContext
  ): Promise<OpenAI.Chat.Completions.ChatCompletionMessageParam[]> {
    const systemPrompt = `Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ù…Ø¨ÙŠØ¹Ø§Øª Ø°ÙƒÙŠ Ù…ØªØ®ØµØµ ÙÙŠ Instagram Ù„Ù„ØªØ¬Ø§Ø± Ø§Ù„Ø¹Ø±Ø§Ù‚ÙŠÙŠÙ†. 

ğŸ¯ Ø®ØµØ§Ø¦Øµ Ø£Ø³Ù„ÙˆØ¨ Instagram:
- Ø£Ø³Ù„ÙˆØ¨ Ø¨ØµØ±ÙŠ ÙˆØ¬Ø°Ø§Ø¨
- Ø§Ø³ØªØ®Ø¯Ø§Ù… ÙƒØ«ÙŠÙ Ù„Ù„Ø±Ù…ÙˆØ² Ø§Ù„ØªØ¹Ø¨ÙŠØ±ÙŠØ© ğŸ˜ğŸ”¥âœ¨
- Ù…Ø­ØªÙˆÙ‰ Ù‚ØµÙŠØ± ÙˆÙ…Ø¤Ø«Ø±
- Ù„ØºØ© Ø¹Ø§Ù…ÙŠØ© Ø¹Ø±Ø§Ù‚ÙŠØ© Ø´Ø¨Ø§Ø¨ÙŠØ©
- ØªØ±ÙƒÙŠØ² Ø¹Ù„Ù‰ Ø§Ù„ØªØ±Ù†Ø¯Ø§Øª ÙˆØ§Ù„Ù…ÙˆØ¶Ø©
- ØªÙØ§Ø¹Ù„ Ø¹Ø§Ø·ÙÙŠ Ù‚ÙˆÙŠ

ğŸ“± Ù†ÙˆØ¹ Ø§Ù„ØªÙØ§Ø¹Ù„: ${context.interactionType}
ğŸª Ø§Ø³Ù… Ø§Ù„Ù…Ø­Ù„: ${context.merchantSettings?.businessName || 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯'}
ğŸ›ï¸ ÙØ¦Ø© Ø§Ù„Ù…Ù†ØªØ¬Ø§Øª: ${context.merchantSettings?.businessCategory || 'Ø¹Ø§Ù…'}
ğŸ“Š Ø¹Ø¯Ø¯ Ø§Ù„Ø·Ù„Ø¨Ø§Øª Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©: ${context.customerProfile?.previousOrders || 0}

ğŸ¨ Ø¥Ø±Ø´Ø§Ø¯Ø§Øª Ø§Ù„Ù…Ø­ØªÙˆÙ‰:
1. Ø§Ø³ØªØ®Ø¯Ù… 3-5 Ø±Ù…ÙˆØ² ØªØ¹Ø¨ÙŠØ±ÙŠØ© ÙÙŠ ÙƒÙ„ Ø±Ø¯
2. Ø§ÙƒØªØ¨ Ø¨Ø£Ø³Ù„ÙˆØ¨ Ø´Ø¨Ø§Ø¨ÙŠ Ø¹Ø±Ø§Ù‚ÙŠ Ù…ÙˆØ¯Ø±Ù†
3. Ø§Ù‚ØªØ±Ø­ Ù…Ø­ØªÙˆÙ‰ Ø¨ØµØ±ÙŠ Ù…Ù†Ø§Ø³Ø¨
4. Ø§Ø±Ø¨Ø· Ø§Ù„Ù…Ù†ØªØ¬Ø§Øª Ø¨Ø§Ù„ØªØ±Ù†Ø¯Ø§Øª Ø§Ù„Ø­Ø§Ù„ÙŠØ©
5. Ø´Ø¬Ø¹ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø´Ø§Ø±ÙƒØ© ÙˆØ§Ù„ØªÙØ§Ø¹Ù„
6. Ø§Ø¬Ø¹Ù„ Ø§Ù„Ø±Ø¯ Ù‚Ø§Ø¨Ù„ Ù„Ù„Ù†Ø´Ø± ÙƒØ³ØªÙˆØ±ÙŠ
7. Ø§Ø³ØªØ®Ø¯Ù… ÙƒÙ„Ù…Ø§Øª ØªØ¬Ø°Ø¨ Ø§Ù„Ø§Ù†ØªØ¨Ø§Ù‡ Ù…Ø«Ù„ "Ø­ØµØ±ÙŠ"ØŒ "ØªØ±Ù†Ø¯"ØŒ "Ø¬Ø¯ÙŠØ¯"

ğŸ’« Ø³ÙŠØ§Ù‚ Ø¨ØµØ±ÙŠ: ${context.mediaContext ? 
  `ÙŠØªÙØ§Ø¹Ù„ Ù…Ø¹ ${context.mediaContext.mediaType} - ${context.mediaContext.caption}` : 
  'Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ù…Ø­ØªÙˆÙ‰ Ø¨ØµØ±ÙŠ'
}

ğŸ¯ ÙŠØ¬Ø¨ Ø£Ù† ØªÙƒÙˆÙ† Ø¥Ø¬Ø§Ø¨ØªÙƒ Ø¨ØµÙŠØºØ© JSON:
{
  "message": "Ø§Ù„Ø±Ø¯ Ø¨Ø£Ø³Ù„ÙˆØ¨ Instagram Ø´Ø¨Ø§Ø¨ÙŠ Ù…Ø¹ Ø±Ù…ÙˆØ² ØªØ¹Ø¨ÙŠØ±ÙŠØ©",
  "messageAr": "Ù†ÙØ³ Ø§Ù„Ø±Ø¯", 
  "intent": "Ù†ÙŠØ© Ø§Ù„Ø¹Ù…ÙŠÙ„",
  "stage": "Ø§Ù„Ù…Ø±Ø­Ù„Ø© Ø§Ù„ØªØ§Ù„ÙŠØ©",
  "actions": [{"type": "Ù†ÙˆØ¹ Ø§Ù„Ø¹Ù…Ù„", "data": {}, "priority": 1}],
  "products": [{"productId": "", "sku": "", "name": "", "price": 0, "confidence": 0.8, "reason": ""}],
  "confidence": 0.9,
  "visualStyle": "story|post|reel|direct",
  "engagement": {
    "likelyToShare": true,
    "viralPotential": 0.8,
    "userGeneratedContent": true
  },
  "mediaRecommendations": [
    {
      "type": "image|video|carousel|story",
      "content": "ÙˆØµÙ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø¨ØµØ±ÙŠ Ø§Ù„Ù…Ù‚ØªØ±Ø­",
      "caption": "Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø±Ø§ÙÙ‚ Ù„Ù„Ù…Ø­ØªÙˆÙ‰",
      "hashtags": ["#ØªØ±Ù†Ø¯", "#Ø¹Ø±Ø§Ù‚"],
      "callToAction": "Ø§Ø¯Ø¹ÙˆØ© Ù„Ù„ØªÙØ§Ø¹Ù„"
    }
  ]
}`;

    const messages: OpenAI.Chat.Completions.ChatCompletionMessageParam[] = [
      { role: 'system', content: systemPrompt }
    ];

    // Add conversation history with Instagram context
    context.conversationHistory.slice(-8).forEach(msg => {
      messages.push({
        role: msg.role,
        content: msg.content
      });
    });

    // Add current customer message with context
    let messageWithContext = customerMessage;
    if (context.interactionType === 'story_reply') {
      messageWithContext = `[Ø±Ø¯Ù‘ Ø¹Ù„Ù‰ Ø³ØªÙˆØ±ÙŠ] ${customerMessage}`;
    } else if (context.interactionType === 'comment') {
      messageWithContext = `[ØªØ¹Ù„ÙŠÙ‚ Ø¹Ù„Ù‰ Ù…Ù†Ø´ÙˆØ±] ${customerMessage}`;
    } else if (context.interactionType === 'story_mention') {
      messageWithContext = `[Ù…Ù†Ø´Ù† ÙÙŠ Ø³ØªÙˆØ±ÙŠ] ${customerMessage}`;
    }

    messages.push({
      role: 'user',
      content: messageWithContext
    });

    return messages;
  }

  /**
   * Private: Build story reply prompt
   */
  private buildStoryReplyPrompt(
    storyReaction: string,
    storyContext: any,
    context: InstagramContext
  ): OpenAI.Chat.Completions.ChatCompletionMessageParam[] {
    return [
      {
        role: 'system',
        content: `Ø£Ù†Øª ØªØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ø±Ø¯Ù‘ Ø¹Ù„Ù‰ Ø³ØªÙˆØ±ÙŠ Instagram. 

ğŸ¬ Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø³ØªÙˆØ±ÙŠ: ${storyContext.mediaType} ${storyContext.caption ? `- "${storyContext.caption}"` : ''}
ğŸ’¬ Ø±Ø¯Ù‘ Ø§Ù„Ø¹Ù…ÙŠÙ„: "${storyReaction}"

ÙŠØ¬Ø¨ Ø£Ù† ÙŠÙƒÙˆÙ† Ø±Ø¯Ùƒ:
- Ù‚ØµÙŠØ± Ø¬Ø¯Ø§Ù‹ (1-2 Ø¬Ù…Ù„Ø©)
- Ù…Ù„ÙŠØ¡ Ø¨Ø§Ù„Ø·Ø§Ù‚Ø© ÙˆØ§Ù„Ø­Ù…Ø§Ø³ ğŸ”¥
- ÙŠØ´Ø¬Ø¹ Ø¹Ù„Ù‰ Ø§Ù„Ù…ØªØ§Ø¨Ø¹Ø© ÙˆØ§Ù„ØªÙØ§Ø¹Ù„
- ÙŠØ±Ø¨Ø· Ø±Ø¯Ù‘Ù‡Ù… Ø¨Ù…Ù†ØªØ¬Ø§ØªÙƒ

Ø£Ø¬Ø¨ Ø¨ØµÙŠØºØ© JSON Ù…Ø¹ message Ù…Ø®ØªØµØ± ÙˆØ­Ù…Ø§Ø³ÙŠ.`
      },
      {
        role: 'user',
        content: `Ø§Ù„Ø±Ø¯Ù‘: "${storyReaction}"`
      }
    ];
  }

  /**
   * Private: Build comment reply prompt
   */
  private buildCommentReplyPrompt(
    commentText: string,
    postContext: any,
    context: InstagramContext
  ): OpenAI.Chat.Completions.ChatCompletionMessageParam[] {
    return [
      {
        role: 'system',
        content: `Ø£Ù†Øª ØªØ±Ø¯Ù‘ Ø¹Ù„Ù‰ ØªØ¹Ù„ÙŠÙ‚ ÙÙŠ Ù…Ù†Ø´ÙˆØ± Instagram.

ğŸ“¸ Ø§Ù„Ù…Ù†Ø´ÙˆØ±: ${postContext.caption ? `"${postContext.caption}"` : 'Ù…Ù†Ø´ÙˆØ± Ø¨Ø¯ÙˆÙ† Ù†Øµ'}
ğŸ’¬ Ø§Ù„ØªØ¹Ù„ÙŠÙ‚: "${commentText}"

ÙŠØ¬Ø¨ Ø£Ù† ÙŠÙƒÙˆÙ† Ø±Ø¯Ùƒ:
- Ù…Ù‡Ø°Ø¨ ÙˆÙ…Ù‡Ù†ÙŠ
- Ù‚ØµÙŠØ± ÙˆÙ…Ø¨Ø§Ø´Ø±
- ÙŠØ¯Ø¹Ùˆ Ù„Ù„ØªÙˆØ§ØµÙ„ Ø§Ù„Ø®Ø§Øµ Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ø³ØªÙØ³Ø§Ø± Ø¬Ø¯ÙŠ
- ÙŠØ­Ø§ÙØ¸ Ø¹Ù„Ù‰ ØµÙˆØ±Ø© Ø§Ù„Ø¹Ù„Ø§Ù…Ø© Ø§Ù„ØªØ¬Ø§Ø±ÙŠØ©

Ø£Ø¬Ø¨ Ø¨ØµÙŠØºØ© JSON Ù…Ø¹ message Ù…Ù†Ø§Ø³Ø¨ Ù„Ù„ØªØ¹Ù„ÙŠÙ‚Ø§Øª Ø§Ù„Ø¹Ø§Ù…Ø©.`
      },
      {
        role: 'user',
        content: `Ø§Ù„ØªØ¹Ù„ÙŠÙ‚: "${commentText}"`
      }
    ];
  }

  /**
   * Private: Build product showcase prompt
   */
  private buildProductShowcasePrompt(
    products: any[],
    context: InstagramContext
  ): OpenAI.Chat.Completions.ChatCompletionMessageParam[] {
    const productsText = products.map(p => 
      `${p.name_ar} - $${p.price_usd} - ${p.category}`
    ).join('\n');

    return [
      {
        role: 'system',
        content: `ØµÙ…Ù… Ù…Ø­ØªÙˆÙ‰ Instagram Ù…Ø¨Ø¯Ø¹ Ù„Ø¹Ø±Ø¶ Ù‡Ø°Ù‡ Ø§Ù„Ù…Ù†ØªØ¬Ø§Øª:

${productsText}

Ø£Ù†Ø´Ø¦:
1. Ø§Ù‚ØªØ±Ø§Ø­Ø§Øª Ù…Ø­ØªÙˆÙ‰ Ø¨ØµØ±ÙŠ (ØµÙˆØ±/ÙÙŠØ¯ÙŠÙˆ)
2. Ù†ØµÙˆØµ Ø¬Ø°Ø§Ø¨Ø© Ù„Ù„Ù…Ù†Ø´ÙˆØ±Ø§Øª
3. Ù‡Ø§Ø´ØªØ§Ø¬Ø§Øª ØªØ±Ù†Ø¯ÙŠÙ†Ø¬ Ø¹Ø±Ø§Ù‚ÙŠØ©
4. Ø·Ø±Ù‚ Ù„Ø²ÙŠØ§Ø¯Ø© Ø§Ù„ØªÙØ§Ø¹Ù„

ÙŠØ¬Ø¨ Ø£Ù† ÙŠÙƒÙˆÙ† Ø§Ù„Ù…Ø­ØªÙˆÙ‰:
- Ø¬Ø°Ø§Ø¨ Ø¨ØµØ±ÙŠØ§Ù‹
- ÙŠØ³ØªÙ‡Ø¯Ù Ø§Ù„Ø¬Ù…Ù‡ÙˆØ± Ø§Ù„Ø¹Ø±Ø§Ù‚ÙŠ Ø§Ù„Ø´Ø§Ø¨
- ÙŠØ´Ø¬Ø¹ Ø¹Ù„Ù‰ Ø§Ù„Ø´Ø±Ø§Ø¡ Ø¯ÙˆÙ† Ø£Ù† ÙŠØ¨Ø¯Ùˆ Ø¥Ø¹Ù„Ø§Ù†Ø§Ù‹
- ÙŠØ³ØªØ®Ø¯Ù… Ø§Ù„ØªØ±Ù†Ø¯Ø§Øª Ø§Ù„Ø­Ø§Ù„ÙŠØ©

Ø£Ø¬Ø¨ Ø¨ØµÙŠØºØ© JSON ÙƒØ§Ù…Ù„Ø©.`
      },
      {
        role: 'user',
        content: 'Ø§Ø¹Ø±Ø¶ Ù‡Ø°Ù‡ Ø§Ù„Ù…Ù†ØªØ¬Ø§Øª Ø¨Ø·Ø±ÙŠÙ‚Ø© Ø¥Ø¨Ø¯Ø§Ø¹ÙŠØ© Ø¹Ù„Ù‰ Instagram'
      }
    ];
  }

  /**
   * Private: Build content analysis prompt
   */
  private buildContentAnalysisPrompt(
    content: string,
    contentType: string,
    context: InstagramContext
  ): OpenAI.Chat.Completions.ChatCompletionMessageParam[] {
    return [
      {
        role: 'system',
        content: `Ø­Ù„Ù„ Ù‡Ø°Ø§ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ù„Ù€ Instagram Ù…Ù† Ù†Ø§Ø­ÙŠØ©:

1. Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„Ù…ØªÙˆÙ‚Ø¹Ø© (Viral Score 0-10)
2. Ù…Ø¹Ø¯Ù„ Ø§Ù„ØªÙØ§Ø¹Ù„ Ø§Ù„Ù…ØªÙˆÙ‚Ø¹ (0-10) 
3. Ù…Ù†Ø§Ø³Ø¨Ø© Ù„Ù„Ø¬Ù…Ù‡ÙˆØ± Ø§Ù„Ø¹Ø±Ø§Ù‚ÙŠ (0-10)
4. Ø§Ù‚ØªØ±Ø§Ø­Ø§Øª Ù„Ù„ØªØ­Ø³ÙŠÙ†

Ø§Ù„Ù…Ø­ØªÙˆÙ‰: "${content}"
Ø§Ù„Ù†ÙˆØ¹: ${contentType}

Ø£Ø¬Ø¨ Ø¨ØµÙŠØºØ© JSON:
{
  "viralScore": 0-10,
  "engagementPrediction": 0-10, 
  "audienceMatch": 0-10,
  "optimizationSuggestions": ["Ø§Ù‚ØªØ±Ø§Ø­ 1", "Ø§Ù‚ØªØ±Ø§Ø­ 2"]
}`
      },
      {
        role: 'user',
        content: `Ø­Ù„Ù„ Ù‡Ø°Ø§ Ø§Ù„Ù…Ø­ØªÙˆÙ‰: "${content}"`
      }
    ];
  }

  /**
   * Private: Generate relevant hashtags
   */
  private async generateRelevantHashtags(
    message: string,
    context: InstagramContext
  ): Promise<string[]> {
    try {
      // Base hashtags for Iraqi market
      const baseHashtags = ['#Ø¹Ø±Ø§Ù‚', '#Ø¨ØºØ¯Ø§Ø¯', '#Ø§Ù„Ø¹Ø±Ø§Ù‚', '#ØªØ³ÙˆÙ‚'];
      
      // Category-specific hashtags
      const categoryHashtags: Record<string, string[]> = {
        fashion: ['#Ù…ÙˆØ¶Ø©', '#Ø£Ø²ÙŠØ§Ø¡', '#Ø³ØªØ§ÙŠÙ„', '#Ù…ÙˆØ¶Ø©_Ø¹Ø±Ø§Ù‚ÙŠØ©'],
        electronics: ['#Ø¬ÙˆØ§Ù„Ø§Øª', '#ØªÙƒÙ†ÙˆÙ„ÙˆØ¬ÙŠØ§', '#Ø§Ù„ÙƒØªØ±ÙˆÙ†ÙŠØ§Øª'],
        beauty: ['#Ø¬Ù…Ø§Ù„', '#Ù…ÙƒÙŠØ§Ø¬', '#Ø¹Ù†Ø§ÙŠØ©', '#ØªØ¬Ù…ÙŠÙ„'],
        food: ['#Ø·Ø¹Ø§Ù…', '#Ø­Ù„ÙˆÙŠØ§Øª', '#Ø§ÙƒÙ„_Ø¹Ø±Ø§Ù‚ÙŠ'],
        home: ['#Ù…Ù†Ø²Ù„', '#Ø¯ÙŠÙƒÙˆØ±', '#ØªØ£Ø«ÙŠØ«']
      };

      const category = context.merchantSettings?.businessCategory || 'general';
      const relevantHashtags = categoryHashtags[category] || [];

      // Trending hashtags (this could be enhanced with real-time trend data)
      const trendingHashtags = ['#ØªØ±Ù†Ø¯', '#Ø¬Ø¯ÙŠØ¯', '#Ø­ØµØ±ÙŠ', '#Ø¹Ø±Ø¶_Ø®Ø§Øµ'];

      return [...baseHashtags, ...relevantHashtags, ...trendingHashtags].slice(0, 8);
    } catch (error) {
      console.error('âŒ Hashtag generation failed:', error);
      return ['#Ø¹Ø±Ø§Ù‚', '#ØªØ³ÙˆÙ‚', '#Ø¬Ø¯ÙŠØ¯'];
    }
  }

  /**
   * Private: Get products for showcase - optimized with batching
   */
  private async getProductsForShowcase(productIds: string[], merchantId: string): Promise<any[]> {
    try {
      const sql = this.db.getSQL();
      
      // Batch multiple queries if needed
      const batchSize = 50; // Limit batch size for performance
      const productBatches = [];
      
      for (let i = 0; i < productIds.length; i += batchSize) {
        const batch = productIds.slice(i, i + batchSize);
        productBatches.push(batch);
      }
      
      let allProducts: any[] = [];
      
      // Process batches concurrently for better performance
      const batchPromises = productBatches.map(batch => 
        sql`
          SELECT id, sku, name_ar, price_usd, category, description_ar, image_urls
          FROM products 
          WHERE id = ANY(${batch}) 
          AND merchant_id = ${merchantId}::uuid 
          AND status = 'ACTIVE'
          ORDER BY is_featured DESC
        `
      );
      
      const batchResults = await Promise.all(batchPromises);
      batchResults.forEach(batch => allProducts.push(...batch));
      
      return allProducts;
    } catch (error) {
      console.error('âŒ Error fetching showcase products:', error);
      return [];
    }
  }

  /**
   * âœ… 3. Performance Optimization: Batch process multiple operations
   */
  private async processCommentBatch(operations: Array<() => Promise<any>>): Promise<any[]> {
    try {
      // Execute operations in parallel for better performance
      return await Promise.all(operations);
    } catch (error) {
      console.error('âŒ Batch processing failed:', error);
      return [];
    }
  }

  /**
   * Private: Log Instagram AI interaction - optimized for batching
   */
  private async logInstagramAIInteraction(
    context: InstagramContext,
    input: string,
    response: InstagramAIResponse
  ): Promise<void> {
    try {
      const sql = this.db.getSQL();
      
      // âœ… 3. Performance: Batch multiple logging operations
      const operations = [
        // Store the main interaction log
        () => sql`
          INSERT INTO audit_logs (
            merchant_id,
            action,
            entity_type,
            details,
            execution_time_ms,
            success
          ) VALUES (
            ${context.merchantId}::uuid,
            'INSTAGRAM_AI_RESPONSE_GENERATED',
            'AI_INTERACTION',
            ${JSON.stringify({
              input: input.substring(0, 200),
              intent: response.intent,
              stage: response.stage,
              tokens: response.tokens,
              confidence: response.confidence,
              platform: 'instagram',
              interactionType: context.interactionType,
              visualStyle: response.visualStyle,
              engagement: response.engagement,
              mediaRecommendations: response.mediaRecommendations?.length || 0,
              hashtagsGenerated: response.hashtagSuggestions?.length || 0
            })},
            ${response.responseTime},
            true
          )
        `,
        
        // Update analytics in the same batch
        () => sql`
          INSERT INTO instagram_analytics (
            merchant_id,
            interaction_type,
            tokens_used,
            response_time_ms,
            created_at
          ) VALUES (
            ${context.merchantId}::uuid,
            ${context.interactionType},
            ${response.tokens?.total || 0},
            ${response.responseTime},
            NOW()
          )
          ON CONFLICT (merchant_id, DATE(created_at)) 
          DO UPDATE SET
            total_interactions = instagram_analytics.total_interactions + 1,
            total_tokens = instagram_analytics.total_tokens + ${response.tokens?.total || 0},
            avg_response_time = (instagram_analytics.avg_response_time + ${response.responseTime}) / 2
        `
      ];

      // Execute all operations in batch
      await this.processCommentBatch(operations);
      
    } catch (error) {
      console.error('âŒ Instagram AI interaction logging failed:', error);
    }
  }

  /**
   * Private: Get Instagram-specific fallback response
   */
  private getInstagramFallbackResponse(context: InstagramContext): InstagramAIResponse {
    const fallbackMessages = [
      'Ø¹Ø°Ø±Ø§Ù‹ Ø­Ø¨ÙŠØ¨ÙŠ ğŸ™ ØµØ§Ø± Ø®Ø·Ø£ ØªÙ‚Ù†ÙŠ Ø¨Ø³ÙŠØ·ØŒ Ø§Ø±Ø³Ù„ Ø±Ø³Ø§Ù„ØªÙƒ Ù…Ø±Ø© Ø«Ø§Ù†ÙŠØ© ğŸ’•',
      'Ø¢Ø³Ù Ø¹Ø²ÙŠØ²ÙŠ ğŸ˜… Ù…Ø§ ÙÙ‡Ù…Øª Ø·Ù„Ø¨Ùƒ Ø¨ÙˆØ¶ÙˆØ­ØŒ Ù…Ù…ÙƒÙ† ØªØ¹ÙŠØ¯Ù„ÙŠ Ø¥ÙŠØ§Ù‡ØŸ ğŸ¤”',
      'ÙÙŠ Ù…Ø´ÙƒÙ„Ø© ØªÙ‚Ù†ÙŠØ© ØµØºÙŠØ±Ø© Ø¹Ù†Ø¯Ù†Ø§ ğŸ”§ Ø¨Ø³ Ø±Ø§Ø­ Ù†Ø­Ù„Ù‡Ø§ Ø¨Ø³Ø±Ø¹Ø©ØŒ Ø§Ù†ØªØ¸Ø±Ù†Ø§ Ø´ÙˆÙŠØ© ğŸ˜Š'
    ];

    const message = fallbackMessages[Math.floor(Math.random() * fallbackMessages.length)];

    return {
      message,
      messageAr: message,
      intent: 'SUPPORT',
      stage: context.stage,
      actions: [{ type: 'ESCALATE', data: { reason: 'AI_ERROR' }, priority: 1 }],
      products: [],
      confidence: 0.1,
      tokens: { prompt: 0, completion: 0, total: 0 },
      responseTime: 0,
      visualStyle: 'direct',
      engagement: {
        likelyToShare: false,
        viralPotential: 0,
        userGeneratedContent: false
      },
      hashtagSuggestions: ['#Ø¹Ø°Ø±', '#Ù…Ø³Ø§Ø¹Ø¯Ø©']
    };
  }
}

// Singleton instance
let instagramAIServiceInstance: InstagramAIService | null = null;

/**
 * Get Instagram AI service instance
 */
export function getInstagramAIService(): InstagramAIService {
  if (!instagramAIServiceInstance) {
    instagramAIServiceInstance = new InstagramAIService();
  }
  return instagramAIServiceInstance;
}

export default InstagramAIService;