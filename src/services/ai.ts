/**
 * ===============================================
 * AI Service - OpenAI Integration for Sales Assistant
 * Secure AI conversation handling with Arabic support
 * ===============================================
 */

import OpenAI from 'openai';
import SmartProductSearch from './search/smart-product-search.js';
import ErrorFallbacksService from './error-fallbacks.js';
import type { ConversationStage, Platform } from '../types/database.js';
import type { DIContainer } from '../container/index.js';
import type { Pool } from 'pg';
import type { AppConfig } from '../config/index.js';
import { getLogger } from './logger.js';

// Type definitions for better type safety
export interface AIResponse {
  message: string;
  messageAr: string;
  intent: string;
  stage: ConversationStage;
  actions: AIAction[];
  products: ProductRecommendation[];
  confidence: number;
  tokens: {
    prompt: number;
    completion: number;
    total: number;
  };
  responseTime: number;
}

export interface AIAction {
  type: 'ADD_TO_CART' | 'SHOW_PRODUCT' | 'CREATE_ORDER' | 'COLLECT_INFO' | 'ESCALATE' | 'SCHEDULE_TEMPLATE';
  data: Record<string, unknown>;
  priority: number;
}

export interface ProductRecommendation {
  productId: string;
  sku: string;
  name: string;
  price: number;
  confidence: number;
  reason: string;
}

export interface ImageData {
  url?: string; // remote URL
  base64?: string; // raw base64 without data URL prefix
  mimeType?: string; // e.g., image/png, image/jpeg
  width?: number;
  height?: number;
  sizeBytes?: number;
  caption?: string;
}

export interface ConversationContext {
  merchantId: string;
  customerId: string;
  platform: Platform;
  stage: ConversationStage;
  cart: Record<string, unknown>[];
  preferences: Record<string, unknown>;
  conversationHistory: MessageHistory[];
  customerProfile?: CustomerProfile;
  merchantSettings?: MerchantSettings;
  imageData?: ImageData[]; // Optional images attached to the current message
}

export interface MessageHistory {
  role: 'user' | 'assistant' | 'system';
  content: string;
  timestamp: Date;
  metadata?: Record<string, unknown>;
}

export interface CustomerProfile {
  name?: string;
  phone?: string;
  instagram?: string;
  previousOrders: number;
  averageOrderValue: number;
  preferredCategories: string[];
  lastInteraction: Date;
}

export interface MerchantSettings {
  businessName: string;
  businessCategory: string;
  workingHours: Record<string, unknown>;
  paymentMethods: string[];
  deliveryFees: Record<string, unknown>;
  autoResponses: Record<string, unknown>;
}

export interface Product {
  id: string;
  sku: string;
  name_ar: string;
  price_usd: number;
  category: string;
  stock_quantity: number;
}

export interface ProductSummary {
  category: string;
  count: number;
  avg_price: number;
}

export interface IntentAnalysisResult {
  intent: string;
  confidence: number;
  entities: Record<string, unknown>;
  stage: ConversationStage;
}

export interface AIRecommendationResponse {
  recommendations: ProductRecommendation[];
}

export class AIService {
  protected openai: OpenAI;
  protected pool: Pool;
  private config: AppConfig;
  private logger = getLogger({ component: 'ai-service' });
  private db: { query: (sql: string, params?: unknown[]) => Promise<unknown[]> };
  
  // Performance optimization: Product caching with size limit
  private productCache = new Map<string, { products: Product[]; timestamp: number }>();
  private readonly CACHE_TTL = 5 * 60 * 1000; // 5 minutes
  private readonly MAX_CACHE_SIZE = 100;
  private search = new SmartProductSearch();

  constructor(container: DIContainer) {
    // Initialize OpenAI client with proper validation
    const openaiApiKey = process.env.OPENAI_API_KEY;
    if (!openaiApiKey) {
      throw new Error('OPENAI_API_KEY environment variable is required');
    }
    
    this.openai = new OpenAI({
      apiKey: openaiApiKey,
      timeout: 30000, // 30 seconds timeout
    });

    // Initialize database pool with validation
    this.pool = container.get<Pool>('pool');
    if (!this.pool) {
      throw new Error('Database pool not found in container');
    }

    // Initialize configuration with validation
    this.config = container.get<AppConfig>('config');
    if (!this.config) {
      throw new Error('AppConfig not found in container');
    }

    // Validate AI configuration
    if (!this.config.ai?.model) {
      throw new Error('AI model configuration is required');
    }

    if (!this.config.ai?.temperature) {
      throw new Error('AI temperature configuration is required');
    }

    if (!this.config.ai?.maxTokens) {
      throw new Error('AI maxTokens configuration is required');
    }

    // Initialize database interface with proper error handling
    this.db = {
      query: async (sql: string, params?: unknown[]) => {
        const client = await this.pool.connect();
        try {
          const result = await client.query(sql, params);
          return result.rows;
        } catch (error) {
          this.logger.error('Database query failed:', { sql, params, error });
          throw error;
        } finally {
          client.release();
        }
      }
    };

    this.logger.info('AI Service initialized successfully');
  }


  /** Mask PII (phones/IG handles) before logging */
  private maskPII(text: string): string {
    if (!text) return '';
    return String(text)
      .replace(/[\r\n]/g, ' ')
      .replace(/\b(\+?\d[\d\s-]{6,})\b/g, '***redacted-phone***')
      .replace(/@[\w.\-]{3,}/g, '@***redacted***')
      .slice(0, 500);
  }

  /** Analyze customer mood and personality from message */
  private analyzeCustomerMood(message: string, _history: MessageHistory[]): {
    mood: 'happy' | 'neutral' | 'frustrated' | 'excited' | 'hesitant' | 'joking';
    personality: 'formal' | 'casual' | 'friendly' | 'business';
    urgency: 'low' | 'medium' | 'high';
    buyingIntent: 'browsing' | 'comparing' | 'ready' | 'negotiating';
  } {
    const text = message.toLowerCase();
    
    // Detect mood
    let mood: 'happy' | 'neutral' | 'frustrated' | 'excited' | 'hesitant' | 'joking' = 'neutral';
    if (/ğŸ˜‚|ğŸ˜„|ğŸ˜Š|Ù‡Ù‡Ù‡Ù‡|Ø­Ù„Ùˆ|Ø±Ø§Ø¦Ø¹|Ù…Ù…ØªØ§Ø²|ÙˆØ§Ù„Ù„Ù‡ Ø²ÙŠÙ†/.test(text)) mood = 'happy';
    else if (/ğŸ˜|ğŸ”¥|ÙˆØ§Ùˆ|ÙŠØ¬Ù†Ù†|ÙƒÙ„Ø´ Ø­Ù„Ùˆ|Ø£Ø­Ø¨Ù‡/.test(text)) mood = 'excited';
    else if (/ØºØ§Ù„ÙŠ|Ù…ÙƒÙ„Ù|Ù…Ø§ Ø¹Ù†Ø¯ÙŠ|ØµØ¹Ø¨|Ù…Ø´ Ù…ØªØ£ÙƒØ¯/.test(text)) mood = 'hesitant';
    else if (/ğŸ˜¤|Ø²Ø¹Ù„Ø§Ù†|Ù…Ùˆ Ø­Ù„Ùˆ|Ø³ÙŠØ¡|Ù…Ø´ÙƒÙ„Ø©/.test(text)) mood = 'frustrated';
    else if (/Ù‡Ù‡Ù‡Ù‡|ğŸ˜‚|Ù…Ø²Ø­|ÙŠØ¶Ø­Ùƒ/.test(text)) mood = 'joking';
    
    // Detect personality
    let personality: 'formal' | 'casual' | 'friendly' | 'business' = 'casual';
    if (/Ø­Ø¶Ø±ØªÙƒ|Ø³ÙŠØ§Ø¯ØªÙƒ|Ø§Ù„Ù…Ø­ØªØ±Ù…/.test(text)) personality = 'formal';
    else if (/Ø­Ø¨ÙŠØ¨ÙŠ|Ø¹Ø²ÙŠØ²ÙŠ|Ø£Ø®ÙŠ|ØµØ¯ÙŠÙ‚ÙŠ/.test(text)) personality = 'friendly';
    else if (/Ø£Ø±ÙŠØ¯|Ø£Ø·Ù„Ø¨|ÙƒÙ… Ø§Ù„Ø³Ø¹Ø±|Ù…ØªÙ‰ Ø§Ù„ØªØ³Ù„ÙŠÙ…/.test(text)) personality = 'business';
    
    // Detect urgency
    let urgency: 'low' | 'medium' | 'high' = 'medium';
    if (/Ø¨Ø³Ø±Ø¹Ø©|Ø¹Ø§Ø¬Ù„|Ø§Ù„ÙŠÙˆÙ…|Ø§Ù„Ø¢Ù†|Ù…Ø³ØªØ¹Ø¬Ù„/.test(text)) urgency = 'high';
    else if (/Ù…ØªÙ‰ Ø´Ø§ÙŠÙ|Ù„Ù…Ø§ Ø£Ù‚Ø¯Ø±|Ø¨Ø§Ù„Ù…Ø³ØªÙ‚Ø¨Ù„/.test(text)) urgency = 'low';
    
    // Detect buying intent
    let buyingIntent: 'browsing' | 'comparing' | 'ready' | 'negotiating' = 'browsing';
    if (/Ø£Ø±ÙŠØ¯ Ø£Ø´ØªØ±ÙŠ|Ø®Ø° Ø·Ù„Ø¨ÙŠ|Ù…ÙˆØ§ÙÙ‚|Ø£ÙˆÙƒÙŠ/.test(text)) buyingIntent = 'ready';
    else if (/ÙƒÙ… Ø§Ù„Ø³Ø¹Ø±|Ø¹Ù†Ø¯ÙƒÙ… Ø£Ø±Ø®Øµ|Ø¨ÙƒÙ…/.test(text)) buyingIntent = 'comparing';
    else if (/Ù…Ù…ÙƒÙ† ØªÙ†Ø²Ù„|Ø®ØµÙ…|ØªØ®ÙÙŠØ¶/.test(text)) buyingIntent = 'negotiating';
    
    return { mood, personality, urgency, buyingIntent };
  }

  /** Generate contextual response based on customer analysis */
  private adaptResponseToCustomer(
    baseResponse: string, 
    customerAnalysis: ReturnType<typeof this.analyzeCustomerMood>
  ): string {
    let adapted = baseResponse;
    
    // Adapt to mood
    if (customerAnalysis.mood === 'excited') {
      adapted = adapted.replace(/\.$/, ' ğŸ”¥');
      if (!adapted.includes('ÙˆØ§Ù„Ù„Ù‡')) adapted = `ÙˆØ§Ù„Ù„Ù‡ ${adapted}`;
    } else if (customerAnalysis.mood === 'hesitant') {
      adapted = `Ù„Ø§ ØªØ´ÙŠÙ„ Ù‡Ù…ØŒ ${adapted}. ÙˆØ¥Ø°Ø§ Ù…Ø§ Ø¹Ø¬Ø¨Ùƒ Ù†Ø±Ø¬Ø¹Ù„Ùƒ ÙÙ„ÙˆØ³Ùƒ`;
    } else if (customerAnalysis.mood === 'frustrated') {
      adapted = `Ø£ÙÙ‡Ù… Ø´Ø¹ÙˆØ±Ùƒ Ø­Ø¨ÙŠØ¨ÙŠØŒ ${adapted}. Ø®Ù„Ù†Ø§ Ù†Ø­Ù„ Ù‡Ø§ÙŠ Ø§Ù„Ù…Ø´ÙƒÙ„Ø© Ø³ÙˆÙŠØ©`;
    } else if (customerAnalysis.mood === 'joking') {
      adapted = `Ù‡Ù‡Ù‡Ù‡ ${adapted} ğŸ˜„`;
    }
    
    // Adapt to personality
    if (customerAnalysis.personality === 'formal') {
      adapted = adapted.replace(/Ø­Ø¨ÙŠØ¨ÙŠ|Ø¹Ø²ÙŠØ²ÙŠ/g, 'Ø£Ø³ØªØ§Ø°');
    } else if (customerAnalysis.personality === 'friendly') {
      if (!adapted.includes('Ø­Ø¨ÙŠØ¨ÙŠ') && Math.random() < 0.7) {
        adapted = adapted.replace(/^/, 'Ø­Ø¨ÙŠØ¨ÙŠØŒ ');
      }
    }
    
    // Adapt to urgency
    if (customerAnalysis.urgency === 'high') {
      adapted = `Ø£ÙƒÙŠØ¯ØŒ ${adapted}. ÙˆØ¨Ø³Ø±Ø¹Ø© Ø¥Ù† Ø´Ø§Ø¡ Ø§Ù„Ù„Ù‡`;
    }
    
    // Adapt to buying intent
    if (customerAnalysis.buyingIntent === 'ready') {
      adapted += '. ØªØ±ÙŠØ¯ Ø£Ø®Ø° Ø·Ù„Ø¨Ùƒ Ø§Ù„Ø¢Ù†ØŸ';
    } else if (customerAnalysis.buyingIntent === 'negotiating') {
      adapted += '. ÙˆØ¹Ù†Ø¯Ù†Ø§ Ø¹Ø±ÙˆØ¶ Ø­Ù„ÙˆØ© Ù„Ù„Ø²Ø¨Ø§Ø¦Ù† Ø§Ù„Ø·ÙŠØ¨ÙŠÙ† Ù…Ø«Ù„Ùƒ';
    }
    
    return adapted;
  }

  /** Remember customer preferences and context */
  private buildSmartMemoryContext(context: ConversationContext): string {
    const history = context.conversationHistory.slice(-10);
    const customerMessages = history.filter(h => h.role === 'user').map(h => h.content);
    
    // Extract preferences from conversation
    const preferences: string[] = [];
    const mentionedProducts: string[] = [];
    
    customerMessages.forEach(msg => {
      const text = msg.toLowerCase();
      
      // Extract product mentions
      if (/Ù‚Ù…ÙŠØµ|Ø¨Ù†Ø·Ù„ÙˆÙ†|Ø­Ø°Ø§Ø¡|Ø¬Ø§Ù†ØªÙŠ|ÙØ³ØªØ§Ù†/.test(text)) {
        const products = text.match(/Ù‚Ù…ÙŠØµ|Ø¨Ù†Ø·Ù„ÙˆÙ†|Ø­Ø°Ø§Ø¡|Ø¬Ø§Ù†ØªÙŠ|ÙØ³ØªØ§Ù†/g);
        if (products) mentionedProducts.push(...products);
      }
    });
    const priceRange: string[] = [];
    
    customerMessages.forEach(msg => {
      const text = msg.toLowerCase();
      
      // Extract color preferences
      if (/Ø£Ø³ÙˆØ¯|Ø£Ø¨ÙŠØ¶|Ø£Ø­Ù…Ø±|Ø£Ø²Ø±Ù‚|Ø£Ø®Ø¶Ø±|Ø£ØµÙØ±/.test(text)) {
        const colors = text.match(/Ø£Ø³ÙˆØ¯|Ø£Ø¨ÙŠØ¶|Ø£Ø­Ù…Ø±|Ø£Ø²Ø±Ù‚|Ø£Ø®Ø¶Ø±|Ø£ØµÙØ±/g);
        if (colors) preferences.push(`ÙŠØ­Ø¨ Ø§Ù„Ø£Ù„ÙˆØ§Ù†: ${colors.join('ØŒ ')}`);
      }
      
      // Extract size preferences
      if (/ØµØºÙŠØ±|Ù…ØªÙˆØ³Ø·|ÙƒØ¨ÙŠØ±|Ù„Ø§Ø±Ø¬|Ù…ÙŠØ¯ÙŠÙˆÙ…|Ø³Ù…ÙˆÙ„/.test(text)) {
        const sizes = text.match(/ØµØºÙŠØ±|Ù…ØªÙˆØ³Ø·|ÙƒØ¨ÙŠØ±|Ù„Ø§Ø±Ø¬|Ù…ÙŠØ¯ÙŠÙˆÙ…|Ø³Ù…ÙˆÙ„/g);
        if (sizes) preferences.push(`Ø§Ù„Ù…Ù‚Ø§Ø³Ø§Øª Ø§Ù„Ù…ÙØ¶Ù„Ø©: ${sizes.join('ØŒ ')}`);
      }
      
      // Extract budget hints
      if (/\d+/.test(text)) {
        const numbers = text.match(/\d+/g);
        if (numbers) priceRange.push(`Ù…ÙŠØ²Ø§Ù†ÙŠØ© Ø­ÙˆØ§Ù„ÙŠ: ${numbers.join('-')} Ø¯ÙŠÙ†Ø§Ø±`);
      }
    });
    
    const memoryParts = [];
    if (preferences.length) memoryParts.push(`Ø§Ù„ØªÙØ¶ÙŠÙ„Ø§Øª: ${preferences.join('ØŒ ')}`);
    if (priceRange.length) memoryParts.push(priceRange[priceRange.length - 1]);
    if (mentionedProducts.length) memoryParts.push(`Ù…Ù†ØªØ¬Ø§Øª Ù…Ø°ÙƒÙˆØ±Ø©: ${mentionedProducts.slice(0, 3).join('ØŒ ')}`);
    
    return memoryParts.length ? memoryParts.join(' | ') : 'Ø²Ø¨ÙˆÙ† Ø¬Ø¯ÙŠØ¯';
  }

  /** Add smart selling techniques */
  private addSellingIntelligence(
    response: string, 
    customerMessage: string
  ): string {
    const text = customerMessage.toLowerCase();
    let enhanced = response;
    
    // Handle price objections smartly
    if (/ØºØ§Ù„ÙŠ|Ù…ÙƒÙ„Ù|Ø£Ø±Ø®Øµ/.test(text)) {
      const techniques = [
        'ÙˆØ§Ù„Ù„Ù‡ Ø§Ù„Ø¬ÙˆØ¯Ø© ØªØ³ØªØ§Ù‡Ù„ Ù‡Ø§ÙŠ Ø§Ù„ÙÙ„ÙˆØ³',
        'Ø´ÙˆÙ Ø­Ø¨ÙŠØ¨ÙŠØŒ Ù‡Ø§ÙŠ Ø§Ù„Ù‚Ø·Ø¹Ø© Ø±Ø§Ø­ ØªØ¶Ù„ Ù…Ø¹Ùƒ Ø³Ù†ÙŠÙ†',
        'Ø¥Ø°Ø§ ØªØ­Ø³Ø¨ Ø§Ù„Ø³Ø¹Ø± Ø¹Ù„Ù‰ Ø§Ù„Ø§Ø³ØªØ¹Ù…Ø§Ù„ØŒ Ø±Ø§Ø­ ØªÙ„Ø§Ù‚ÙŠÙ‡ Ø±Ø®ÙŠØµ ÙƒÙ„Ø´',
        'ÙˆØ¹Ù†Ø¯Ù†Ø§ Ø¶Ù…Ø§Ù† ÙˆØ¥Ø°Ø§ Ù…Ø§ Ø¹Ø¬Ø¨Ùƒ Ù†Ø±Ø¬Ø¹Ù„Ùƒ ÙÙ„ÙˆØ³Ùƒ'
      ];
      enhanced += '. ' + techniques[Math.floor(Math.random() * techniques.length)];
    }
    
    // Handle hesitation with reassurance
    if (/Ù…Ø´ Ù…ØªØ£ÙƒØ¯|Ù…Ø§ Ø£Ø¯Ø±ÙŠ|Ø®Ù„Ù†ÙŠ Ø£ÙÙƒØ±/.test(text)) {
      const reassurance = [
        'Ù„Ø§ ØªØ´ÙŠÙ„ Ù‡Ù…ØŒ Ø®Ø° ÙˆÙ‚ØªÙƒ Ø¨Ø§Ù„ØªÙÙƒÙŠØ±',
        'Ø£Ù†Ø§ Ù‡Ù†Ø§ Ù„Ù…Ø³Ø§Ø¹Ø¯ØªÙƒ Ø¨Ø£ÙŠ Ø´ÙŠ',
        'Ù…Ø§ÙÙŠ Ø¹Ø¬Ù„Ø©ØŒ Ø§Ù„Ù…Ù‡Ù… ØªÙ„Ø§Ù‚ÙŠ Ø§Ù„Ù„ÙŠ ÙŠØ¹Ø¬Ø¨Ùƒ',
        'ÙˆØ¥Ø°Ø§ Ø­Ø¨ÙŠØª ØªØ´ÙˆÙ Ù‚Ø·Ø¹ Ø«Ø§Ù†ÙŠØ©ØŒ Ø£Ù†Ø§ Ù…ÙˆØ¬ÙˆØ¯'
      ];
      enhanced += '. ' + reassurance[Math.floor(Math.random() * reassurance.length)];
    }
    
    // Create urgency for interested customers
    if (/Ø­Ù„Ùˆ|ÙŠØ¹Ø¬Ø¨Ù†ÙŠ|Ø£Ø­Ø¨Ù‡|Ø±Ø§Ø¦Ø¹/.test(text)) {
      const urgency = [
        'ÙˆÙ‡Ø§ÙŠ Ø§Ù„Ù‚Ø·Ø¹Ø© Ø¹Ù„ÙŠÙ‡Ø§ Ø¥Ù‚Ø¨Ø§Ù„ ÙƒØ¨ÙŠØ±',
        'Ø¨ØµØ±Ø§Ø­Ø©ØŒ Ù…Ø§ Ø¨Ù‚Ù‰ Ù…Ù†Ù‡Ø§ ÙƒØ«ÙŠØ±',
        'ÙˆØ§Ù„Ù„Ù‡ Ù‡Ø§ÙŠ Ù…Ù† Ø£Ø­Ø³Ù† Ø§Ù„Ù‚Ø·Ø¹ Ø¹Ù†Ø¯Ù†Ø§',
        'ÙˆØ¹Ù†Ø¯Ù†Ø§ Ø¹Ø±Ø¶ Ø®Ø§Øµ Ù„Ù‡Ø§ÙŠ Ø§Ù„Ø£ÙŠØ§Ù…'
      ];
      if (Math.random() < 0.6) {
        enhanced += '. ' + urgency[Math.floor(Math.random() * urgency.length)];
      }
    }
    
    // Handle comparison shopping
    if (/Ø¹Ù†Ø¯ ØºÙŠØ±ÙƒÙ…|ÙÙŠ Ù…Ø­Ù„ Ø«Ø§Ù†ÙŠ|Ø£Ø±Ø®Øµ Ù…Ù†ÙƒÙ…/.test(text)) {
      const competitive = [
        'Ø£ÙƒÙŠØ¯ Ø±Ø§Ø­ ØªÙ„Ø§Ù‚ÙŠ Ø£Ø±Ø®ØµØŒ Ø¨Ø³ Ø§Ù„Ø¬ÙˆØ¯Ø© Ù…Ùˆ Ø²ÙŠ Ø¨Ø¹Ø¶',
        'Ø§Ø­Ù†Ø§ Ù†Ø±ÙƒØ² Ø¹Ù„Ù‰ Ø§Ù„Ø¬ÙˆØ¯Ø© Ù…Ø´ Ø¨Ø³ Ø§Ù„Ø³Ø¹Ø±',
        'ÙˆØ¹Ù†Ø¯Ù†Ø§ Ø®Ø¯Ù…Ø© Ø¨Ø¹Ø¯ Ø§Ù„Ø¨ÙŠØ¹ Ù…Ø§ ØªÙ„Ø§Ù‚ÙŠÙ‡Ø§ Ø¨Ù…Ø­Ù„',
        'Ø¬Ø±Ø¨ ÙˆØ´ÙˆÙØŒ ÙˆØ¥Ø°Ø§ Ù…Ø§ Ø¹Ø¬Ø¨Ùƒ Ù†Ø±Ø¬Ø¹Ù„Ùƒ ÙÙ„ÙˆØ³Ùƒ'
      ];
      enhanced += '. ' + competitive[Math.floor(Math.random() * competitive.length)];
    }
    
    return enhanced;
  }

  /** Add natural conversation flow */
  private makeConversationNatural(
    response: string,
    customerMessage: string,
    history: MessageHistory[]
  ): string {
    let natural = response;
    
    // Add natural transitions
    const recentMessages = history.slice(-3).map(h => h.content.toLowerCase());
    const hasRepeatedQuestion = recentMessages.some(msg => 
      customerMessage.toLowerCase().includes(msg.substring(0, 10))
    );
    
    if (hasRepeatedQuestion) {
      const acknowledgments = [
        'Ø²ÙŠ Ù…Ø§ Ù‚Ù„ØªÙ„ÙƒØŒ',
        'Ù…Ø«Ù„ Ù…Ø§ Ø°ÙƒØ±ØªÙ„ÙƒØŒ',
        'Ù†Ø¹Ù… Ø­Ø¨ÙŠØ¨ÙŠØŒ',
        'Ø£ÙƒÙŠØ¯ØŒ'
      ];
      natural = acknowledgments[Math.floor(Math.random() * acknowledgments.length)] + ' ' + natural;
    }
    
    // Add conversation continuers
    if (Math.random() < 0.3) {
      const continuers = [
        'Ø´Ù†Ùˆ Ø±Ø£ÙŠÙƒØŸ',
        'Ø¹Ù†Ø¯Ùƒ Ø£ÙŠ Ø³Ø¤Ø§Ù„ Ø«Ø§Ù†ÙŠØŸ',
        'ØªØ­Ø¨ Ø£ÙˆØ±ÙŠÙƒ Ø´ÙŠ Ø«Ø§Ù†ÙŠØŸ',
        'ÙˆØ´Ù†Ùˆ Ø±Ø£ÙŠÙƒ Ø¨Ø§Ù„Ù„ÙˆÙ†ØŸ'
      ];
      natural += ' ' + continuers[Math.floor(Math.random() * continuers.length)];
    }
    
    return natural;
  }

  /** Exponential backoff retry helper */
  private async withRetry<T>(fn: () => Promise<T>, label: string, max = 3, timeout = 30000): Promise<T> {
    let attempt = 0;
    let lastErr: unknown;
    while (attempt < max) {
      try {
        // âœ… Ø¥Ø¶Ø§ÙØ© timeout Ù„Ù„Ø¹Ù…Ù„ÙŠØ© Ù†ÙØ³Ù‡Ø§
        const controller = new AbortController();
        const timeoutId = setTimeout(() => controller.abort(), timeout);
        
        const result = await Promise.race([
          fn(),
          new Promise<never>((_, reject) => {
            controller.signal.addEventListener('abort', () => {
              reject(new Error(`${label} timeout after ${timeout}ms`));
            });
          })
        ]);
        
        clearTimeout(timeoutId);
        return result;
      } catch (e: unknown) {
        lastErr = e;
        const msg = String((e as { message?: string })?.message || e);
        const retriable = /rate limit|timeout|ETIMEDOUT|ECONNRESET|ENETUNREACH|EAI_AGAIN/i.test(msg);
        if (!retriable) break;
        const delay = Math.min(2000 * Math.pow(2, attempt), 8000);
        this.logger.warn(`Retrying ${label} after ${delay}ms (attempt ${attempt + 1})`, { msg });
        await new Promise(r => setTimeout(r, delay));
      }
      attempt++;
    }
    throw lastErr instanceof Error ? lastErr : new Error(`${label} failed`);
  }

  /** Check if AI processing is enabled for merchant */
  private async isAIEnabled(merchantId: string): Promise<boolean> {
    try {
      const { getServiceController } = await import('./service-controller.js');
      const sc = getServiceController();
      return await sc.isServiceEnabled(merchantId, 'AI_RESPONSES');
    } catch (error: unknown) {
      this.logger.warn('Failed to check AI service status, defaulting to enabled:', { merchantId, error });
      return true;
    }
  }

  /**
   * Generate AI response for customer message
   */
  public async generateResponse(
    customerMessage: string,
    context: ConversationContext
  ): Promise<AIResponse> {
    const startTime = Date.now();

    try {
      // Service enablement check
      if (!(await this.isAIEnabled(context.merchantId))) {
        this.logger.warn('AI disabled by ServiceController; sending user notification', { 
          merchantId: context.merchantId 
        });
        
        const fallbackResponse = await this.getEnhancedFallbackResponse(context, customerMessage);
        
        // ØªØ£ÙƒØ¯ Ù…Ù† Ø¥ÙŠØµØ§Ù„ Ø§Ù„Ø±Ø³Ø§Ù„Ø© Ù„Ù„Ù…Ø³ØªØ®Ø¯Ù…
        await this.notifyUserAIDisabled(context);
        
        return fallbackResponse;
      }

      // Lightweight intent analysis to guide downstream behavior
      let analyzedIntent: IntentAnalysisResult | undefined;
      try { 
        analyzedIntent = await this.analyzeIntent(customerMessage, context);
        this.logger.debug('Intent analysis successful', { 
          intent: analyzedIntent.intent, 
          confidence: analyzedIntent.confidence 
        });
      } catch (error) {
        this.logger.warn('Intent analysis failed, continuing without intent', { 
          error: String(error),
          customerMessage: this.maskPII(customerMessage)
        });
        // Ø¥Ù†Ø´Ø§Ø¡ intent Ø§ÙØªØ±Ø§Ø¶ÙŠ Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† ØªØ¬Ø§Ù‡Ù„ Ø§Ù„Ø®Ø·Ø£
        analyzedIntent = {
          intent: 'CONVERSATION',
          confidence: 0.5,
          entities: {},
          stage: context.stage
        };
      }

      // Build conversation prompt (text + optional vision parts)
      const prompt = await this.buildConversationPrompt(customerMessage, context);

      // Call OpenAI API with timeout + retry
      const controller = new AbortController();
      const timeout = this.config.ai.timeout || 30000;
      const timer = setTimeout(() => controller.abort(), timeout);
      
      const useVision = Array.isArray(context.imageData) && context.imageData.length > 0;
      // Best-effort vision product analysis to enrich results
      let visionProducts: { id: string; sku: string; name_ar: string; effective_price?: number; price_currency?: string; stock_quantity: number }[] = [];
      let visionInfo: { ocrText?: string; defects?: { hasDefect: boolean; notes: string[] } } | null = null;
      if (useVision) {
        try {
          const { getInstagramAIService } = await import('./instagram-ai.js');
          const ig = getInstagramAIService();
          const analysis = await ig.analyzeImagesGeneric(context.merchantId, context.imageData!, customerMessage);
          visionProducts = analysis.candidates || [];
          visionInfo = { ocrText: analysis.ocrText, defects: analysis.defects };
          this.logger.debug('Vision analysis successful', { 
            productsFound: visionProducts.length,
            hasOCR: !!visionInfo?.ocrText,
            hasDefects: !!visionInfo?.defects?.hasDefect
          });
        } catch (e) {
          this.logger.warn('Vision product analysis failed, continuing without vision data', { 
            error: String(e),
            imageCount: context.imageData?.length || 0
          });
          // Ø¥Ù†Ø´Ø§Ø¡ Ø¨ÙŠØ§Ù†Ø§Øª Ø§ÙØªØ±Ø§Ø¶ÙŠØ© Ù„Ù„Ø±Ø¤ÙŠØ© Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† ØªØ¬Ø§Ù‡Ù„ Ø§Ù„Ø®Ø·Ø£
          visionProducts = [];
          visionInfo = { ocrText: '', defects: { hasDefect: false, notes: [] } };
        }
      }
      const model = useVision ? (this.config.ai.visionModel || 'gpt-4o-mini') : this.config.ai.model;
      // Ø¨Ø§ØªØ´ 4: ØªØ³Ø¬ÙŠÙ„ DEBUG Ù„Ù„Ù€ HTTP Outbound
      this.logger.debug('OpenAI request payload:', { 
        model, 
        messageCount: prompt.length,
        temperature: Math.min(this.config.ai.temperature ?? 0.8, 1.0),
        maxTokens: Math.min(this.config.ai.maxTokens ?? 500, 800),
        presencePenalty: 0.6,
        frequencyPenalty: 0.4
      });

      const completion = await this.withRetry(
        () => this.openai.chat.completions.create({
          model,
          messages: prompt,
          temperature: Math.min(this.config.ai.temperature ?? 0.8, 1.0),
          max_tokens: Math.min(this.config.ai.maxTokens ?? 500, 800),
          top_p: 0.9,
          presence_penalty: 0.6, // Ø²ÙŠØ§Ø¯Ø© Ø¹Ù‚ÙˆØ¨Ø© Ø§Ù„ØªÙƒØ±Ø§Ø±
          frequency_penalty: 0.4, // ØªÙ‚Ù„ÙŠÙ„ ØªÙƒØ±Ø§Ø± Ø§Ù„ÙƒÙ„Ù…Ø§Øª
        }),
        'openai.chat.completions'
      ).finally(() => clearTimeout(timer));

      // Ø¨Ø§ØªØ´ 4: ØªØ³Ø¬ÙŠÙ„ Ø§Ø³ØªØ¬Ø§Ø¨Ø© OpenAI
      this.logger.debug('OpenAI response received:', { 
        usage: completion.usage,
        choicesCount: completion.choices?.length || 0,
        finishReason: completion.choices?.[0]?.finish_reason
      });

      const responseTime = Date.now() - startTime;
      const response = completion.choices?.[0]?.message?.content;

      if (!response) {
        throw new Error('No response from OpenAI');
      }

      // Get the already analyzed customer data and create intelligent response
      let smartResponse = response.trim();
      
      // Apply human-like intelligence enhancements
      if (smartResponse.length < 10) {
        smartResponse = 'Ø£Ù‡Ù„Ø§Ù‹ Ø­Ø¨ÙŠØ¨ÙŠ! Ø´Ù„ÙˆÙ†Ùƒ Ø§Ù„ÙŠÙˆÙ…ØŸ Ø´Ù†Ùˆ Ø£Ù‚Ø¯Ø± Ø£Ø³Ø§Ø¹Ø¯Ùƒ Ø¨ÙŠÙ‡ØŸ';
      }
      
      // Apply customer mood analysis and adaptation
      const customerAnalysis = this.analyzeCustomerMood(customerMessage, context.conversationHistory);
      smartResponse = this.adaptResponseToCustomer(smartResponse, customerAnalysis);
      
      // Add selling intelligence
      smartResponse = this.addSellingIntelligence(smartResponse, customerMessage);
      
      // Make conversation more natural
      smartResponse = this.makeConversationNatural(smartResponse, customerMessage, context.conversationHistory);
      
      const aiResponse: AIResponse = {
        message: smartResponse,
        messageAr: smartResponse,
        intent: analyzedIntent?.intent || 'conversation',
        stage: context.stage,
        actions: [],
        products: [],
        confidence: 0.9,
        tokens: {
          prompt: completion.usage?.prompt_tokens ?? 0,
          completion: completion.usage?.completion_tokens ?? 0,
          total: completion.usage?.total_tokens ?? 0
        },
        responseTime: responseTime
      };

      // Attach visual candidates and signals
      if (visionProducts.length) {
        aiResponse.products = visionProducts.slice(0, 5).map(p => ({
          productId: p.id,
          sku: p.sku,
          name: p.name_ar,
          price: Number(p.effective_price ?? 0),
          confidence: 0.7,
          reason: 'visual_match'
        }));
        aiResponse.actions.push({ type: 'SHOW_PRODUCT', data: { items: aiResponse.products.slice(0, 3) }, priority: 1 });
      }
      if (visionInfo?.ocrText && visionInfo.ocrText.length > 0) {
        aiResponse.actions.push({ type: 'COLLECT_INFO', data: { field: 'ocr_text', value: visionInfo.ocrText.slice(0, 500) }, priority: 2 });
      }
      if (visionInfo?.defects && visionInfo.defects.hasDefect) {
        aiResponse.actions.push({ type: 'ESCALATE', data: { reason: 'defect_detected', notes: (visionInfo.defects.notes || []).slice(0, 3) }, priority: 1 });
      }

      // Auto-suggest products for product-related intents
      try {
        const productIntents = new Set(['PRODUCT_INQUIRY', 'BROWSING', 'PRICE_INQUIRY']);
        if (analyzedIntent && productIntents.has(analyzedIntent.intent)) {
          const recs = await this.generateProductRecommendations(customerMessage, context, 5);
          if (Array.isArray(recs) && recs.length) {
            aiResponse.products = recs;
            aiResponse.actions = [
              { type: 'SHOW_PRODUCT', data: { items: recs.slice(0, 3) }, priority: 1 }
            ];
            this.logger.debug('Product recommendations generated successfully', { 
              count: recs.length,
              intent: analyzedIntent.intent
            });
          }
        }
      } catch (e) {
        this.logger.warn('Auto-suggestions generation failed, trying fallback recommendations', { 
          error: String(e),
          intent: analyzedIntent?.intent
        });
        // Ù…Ø­Ø§ÙˆÙ„Ø© Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù‚ØªØ±Ø§Ø­Ø§Øª Ø¨Ø¯ÙŠÙ„Ø©
        try {
          const fallbackRecs = await this.getFallbackProductRecommendations(context.merchantId, 3);
          if (fallbackRecs.length > 0) {
            aiResponse.products = fallbackRecs;
            aiResponse.actions = [
              { type: 'SHOW_PRODUCT', data: { items: fallbackRecs }, priority: 2 }
            ];
            this.logger.debug('Fallback product recommendations generated', { count: fallbackRecs.length });
          }
        } catch (fallbackError) {
          this.logger.error('Fallback recommendations also failed', { error: String(fallbackError) });
        }
      }
      
      // Simple validation - just check if message exists
      if (!aiResponse.message || aiResponse.message.trim().length === 0) {
        this.logger.error("Empty AI response", { got: aiResponse });
        return await this.getEnhancedFallbackResponse(context, customerMessage);
      }
      
      // Add metadata
      aiResponse.tokens = {
        prompt: completion.usage?.prompt_tokens ?? 0,
        completion: completion.usage?.completion_tokens ?? 0,
        total: completion.usage?.total_tokens ?? 0
      };
      aiResponse.responseTime = responseTime;

      // Post-process: Constitutional AI critique & improvement (best-effort)
      try {
        const { ConstitutionalAI } = await import('./constitutional-ai.js');
        const ca = new ConstitutionalAI();
        const critique = await ca.critiqueResponse(aiResponse.message, { merchantId: context.merchantId });
        if (!critique.meetsThreshold) {
          const improved = await ca.improveResponse(aiResponse.message, critique, { merchantId: context.merchantId });
          aiResponse.message = improved.improved;
          aiResponse.messageAr = improved.improved;
          this.logger.debug('ConstitutionalAI improved response', { 
            originalLength: aiResponse.message.length,
            improvedLength: improved.improved.length
          });
        } else {
          this.logger.debug('ConstitutionalAI response meets quality threshold');
        }
      } catch (e) {
        this.logger.warn('ConstitutionalAI post-process failed, using original response', { 
          error: String(e),
          messageLength: aiResponse.message.length
        });
        // Ø§Ù„Ø§Ø³ØªÙ…Ø±Ø§Ø± Ø¨Ø§Ù„Ø±Ø¯ Ø§Ù„Ø£ØµÙ„ÙŠ Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† ØªØ¬Ø§Ù‡Ù„ Ø§Ù„Ø®Ø·Ø£
      }

      // Post-process: Response diversity improvement
      try {
        const { improveResponseDiversity } = await import('../utils/response-diversity.js');
        const conversationHistory = Array.isArray((context as any)?.conversationHistory) 
          ? (context as any).conversationHistory as Array<{ role: string; content: string; timestamp?: string | Date }>
          : [];
        
        const historyForDiversity = conversationHistory.map(msg => ({
          role: msg.role as 'user' | 'assistant',
          content: msg.content,
          timestamp: msg.timestamp ? new Date(msg.timestamp) : new Date()
        }));
        
        const improvedMessage = improveResponseDiversity(aiResponse.message, historyForDiversity);
        if (improvedMessage !== aiResponse.message) {
          this.logger.debug('Response diversity improved', {
            originalLength: aiResponse.message.length,
            improvedLength: improvedMessage.length
          });
          aiResponse.message = improvedMessage;
          aiResponse.messageAr = improvedMessage;
        } else {
          this.logger.debug('Response diversity already optimal');
        }
      } catch (e) {
        this.logger.warn('Response diversity improvement failed, using original response', { 
          error: String(e),
          historyLength: context.conversationHistory.length
        });
        // Ø§Ù„Ø§Ø³ØªÙ…Ø±Ø§Ø± Ø¨Ø§Ù„Ø±Ø¯ Ø§Ù„Ø£ØµÙ„ÙŠ Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† ØªØ¬Ø§Ù‡Ù„ Ø§Ù„Ø®Ø·Ø£
      }

      // Post-process: Tone & Dialect adaptation (Iraqi/BAGHDADI + tier + sentiment)
      try {
        const { CustomerProfiler } = await import('./customer-profiler.js');
        const { adaptDialectAndTone, detectSentiment } = await import('./tone-dialect.js');
        const profiler = new CustomerProfiler();
        const profile = await profiler.personalizeResponses(context.merchantId, context.customerId);
        const sentiment = detectSentiment(customerMessage);
        const adapted = adaptDialectAndTone(aiResponse.message, {
          dialect: 'baghdadi',
          tier: profile.tier,
          sentiment
        });
        aiResponse.message = adapted;
        aiResponse.messageAr = adapted;
        this.logger.debug('Tone/Dialect adaptation successful', { 
          dialect: 'baghdadi',
          tier: profile.tier,
          sentiment
        });
      } catch (e) {
        this.logger.warn('Tone/Dialect adaptation failed, using original response', { 
          error: String(e),
          customerId: context.customerId
        });
        // Ø§Ù„Ø§Ø³ØªÙ…Ø±Ø§Ø± Ø¨Ø§Ù„Ø±Ø¯ Ø§Ù„Ø£ØµÙ„ÙŠ Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† ØªØ¬Ø§Ù‡Ù„ Ø§Ù„Ø®Ø·Ø£
      }

      // Log AI interaction
      await this.logAIInteraction(context, this.maskPII(customerMessage), aiResponse);

      // Save assistant message in semantic memory (best-effort)
      try {
        const { getSemanticMemoryService } = await import('./semantic-memory.js');
        const mem = getSemanticMemoryService();
        const convId = (context as any)?.conversationId || '00000000-0000-0000-0000-000000000000';
        await mem.saveMessage(context.merchantId, context.customerId, convId, 'assistant', aiResponse.message);
        this.logger.debug('Message saved to semantic memory', { 
          conversationId: convId,
          messageLength: aiResponse.message.length
        });
      } catch (e) {
        this.logger.warn('Failed to save message to semantic memory', { 
          error: String(e),
          conversationId: (context as any)?.conversationId
        });
        // Ø§Ù„Ø§Ø³ØªÙ…Ø±Ø§Ø± Ø¨Ø¯ÙˆÙ† Ø­ÙØ¸ ÙÙŠ Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ø¯Ù„Ø§Ù„ÙŠØ©
      }

      return aiResponse;
    } catch (error: unknown) {
      const err = error instanceof Error ? error : new Error(String(error));
      this.logger.error('AI response generation failed:', {
        error: err.message,
        stack: err.stack,
        merchantId: context.merchantId,
        customerId: context.customerId
      });
      
      // Return fallback response
      return await this.getEnhancedFallbackResponse(context, customerMessage);
    }
  }

  /**
   * Analyze customer intent from message
   */
  public async analyzeIntent(
    customerMessage: string,
    context: ConversationContext
  ): Promise<IntentAnalysisResult> {
    try {
      const prompt = this.buildIntentAnalysisPrompt(customerMessage, context);
      
      const completion = await this.openai.chat.completions.create({
        model: this.config.ai.intentModel || 'gpt-4o-mini',
        messages: prompt,
        temperature: this.config.ai.intentTemperature ?? 0.3,
        max_tokens: this.config.ai.intentMaxTokens || 200,
        response_format: { type: 'json_object' }
      });

      const response = completion.choices?.[0]?.message?.content;
      if (!response) {
        throw new Error('No response from OpenAI for intent analysis');
      }
      
      try {
        const result = JSON.parse(response) as IntentAnalysisResult;
        return result;
      } catch (parseError) {
        this.logger.error('Intent analysis JSON parse failed', { error: parseError, response: response.slice(0, 200) });
        return {
          intent: 'UNKNOWN',
          confidence: 0,
          entities: {},
          stage: context.stage
        };
      }
    } catch (error: unknown) {
      const err = error instanceof Error ? error : new Error(String(error));
      this.logger.error('Intent analysis failed', { 
        error: err.message, 
        customerMessage: this.maskPII(customerMessage),
        merchantId: context.merchantId 
      });
      return {
        intent: 'UNKNOWN',
        confidence: 0,
        entities: {},
        stage: context.stage
      };
    }
  }

  /**
   * Generate product recommendations
   */
  public async generateProductRecommendations(
    customerQuery: string,
    context: ConversationContext,
    maxProducts: number = 5
  ): Promise<ProductRecommendation[]> {
    try {
      // Get merchant's products with caching
      const products = await this.getMerchantProducts(context.merchantId);
      
      const prompt = this.buildProductRecommendationPrompt(
        customerQuery,
        products
      );

      const completion = await this.openai.chat.completions.create({
        model: this.config.ai.recommendationModel || 'gpt-4o-mini',
        messages: prompt,
        temperature: this.config.ai.recommendationTemperature ?? 0.5,
        max_tokens: this.config.ai.recommendationMaxTokens || 300,
        response_format: { type: 'json_object' }
      });

      const response = completion.choices?.[0]?.message?.content;
      if (!response) {
        throw new Error('No response from OpenAI for product recommendations');
      }
      
      try {
        const recommendations = JSON.parse(response) as AIRecommendationResponse;
        if (Array.isArray(recommendations.recommendations)) {
          return recommendations.recommendations.slice(0, maxProducts);
        }
        return [];
      } catch (parseError) {
        this.logger.error('Product recommendations JSON parse failed', { error: parseError, response: response.slice(0, 200) });
        return [];
      }
    } catch (error: unknown) {
      const err = error instanceof Error ? error : new Error(String(error));
      this.logger.error('Product recommendation failed', { 
        error: err.message, 
        customerQuery: this.maskPII(customerQuery),
        merchantId: context.merchantId 
      });
      return [];
    }
  }

  /**
   * Generate conversation summary
   */
  public async generateConversationSummary(
    conversationHistory: MessageHistory[],
    context: ConversationContext
  ): Promise<string> {
    try {
      const prompt = this.buildSummaryPrompt(conversationHistory);
      
      const completion = await this.openai.chat.completions.create({
        model: this.config.ai.summaryModel || 'gpt-4o-mini',
        messages: prompt,
        temperature: this.config.ai.summaryTemperature ?? 0.3,
        max_tokens: this.config.ai.summaryMaxTokens || 200
      });

      return completion.choices[0]?.message?.content || 'Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ù…Ù„Ø®Øµ Ù…ØªØ§Ø­';
    } catch (error: unknown) {
      const err = error instanceof Error ? error : new Error(String(error));
      this.logger.error('Conversation summary failed', { 
        error: err.message, 
        merchantId: context.merchantId,
        historyLength: conversationHistory.length 
      });
      return 'Ø®Ø·Ø£ ÙÙŠ Ø¥Ù†ØªØ§Ø¬ Ø§Ù„Ù…Ù„Ø®Øµ';
    }
  }

  /**
   * Private: Build conversation prompt
   */
  private async buildConversationPrompt(
    customerMessage: string,
    context: ConversationContext
  ): Promise<OpenAI.Chat.Completions.ChatCompletionMessageParam[]> {
    // Persona by merchant type (fallbacks)
    const persona = await this.getMerchantPersona(context.merchantId);
    const memoryLine = this.buildMemoryLine(context.customerProfile);

    // Enrich prompt with business label and relevant products
    const catLabelMap: Record<string, string> = {
      fashion: 'Ù…Ù„Ø§Ø¨Ø³ ÙˆØ£Ø²ÙŠØ§Ø¡', electronics: 'Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠØ§Øª', beauty: 'Ø¬Ù…Ø§Ù„', grocery: 'Ù…ÙˆØ§Ø¯ ØºØ°Ø§Ø¦ÙŠØ©',
      pharmacy: 'ØµÙŠØ¯Ù„ÙŠØ©', toys: 'Ø£Ù„Ø¹Ø§Ø¨', sports: 'Ø±ÙŠØ§Ø¶Ø©', books: 'ÙƒØªØ¨', home: 'Ù…Ù†Ø²Ù„', auto: 'Ø³ÙŠØ§Ø±Ø§Øª',
      electric: 'Ø£Ø¬Ù‡Ø²Ø© ÙƒÙ‡Ø±Ø¨Ø§Ø¦ÙŠØ©', other: 'Ø¹Ø§Ù…'
    };
    const catLabel = catLabelMap[persona.businessCategory] || 'Ø¹Ø§Ù…';
    // Ø¬Ù„Ø¨ Ø§Ø³Ù… Ø§Ù„Ù…ØªØ¬Ø± Ù…Ù† Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª - Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠ Ø¨Ø§Ù„ÙƒØ§Ù…Ù„
    let businessName = 'Ù…ØªØ¬Ø±Ù†Ø§'; // Ù‚ÙŠÙ…Ø© Ø§ÙØªØ±Ø§Ø¶ÙŠØ© ÙÙ‚Ø·
    try {
      const { dynamicTemplateManager } = await import('./dynamic-template-manager.js');
      const defaults = await dynamicTemplateManager.getDefaults(context.merchantId);
      businessName = defaults.businessName;
    } catch (error) {
      this.logger.warn('Failed to get dynamic business name', { error: String(error) });
      businessName = context.merchantSettings?.businessName || 'Ù…ØªØ¬Ø±Ù†Ø§';
    }
    let relevantProducts: Array<Record<string, any>> = [];
    try { 
      relevantProducts = await this.searchRelevantProducts(customerMessage, context.merchantId, 5);
      this.logger.debug('Relevant products found', { count: relevantProducts.length });
    } catch (e) {
      this.logger.warn('Product search failed, using empty product list', { 
        error: String(e),
        query: this.maskPII(customerMessage)
      });
      relevantProducts = [];
    }
    const productInfo = this.formatProductsForPrompt(relevantProducts);
    const newSystemPrompt = `Ø£Ù†Øª Ø¨Ø§Ø¦Ø¹ Ø¹Ø±Ø§Ù‚ÙŠ Ø°ÙƒÙŠ ÙˆØ·Ø¨ÙŠØ¹ÙŠ ÙÙŠ Ù…ØªØ¬Ø± ${businessName} (${catLabel}). ØªØªÙƒÙ„Ù… Ù…Ø«Ù„ Ø§Ù„Ø¥Ù†Ø³Ø§Ù† Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠ.\n\nğŸ“¦ Ø§Ù„Ù…Ù†ØªØ¬Ø§Øª Ø§Ù„Ù…ØªÙˆÙØ±Ø©:\n${productInfo}\n\nğŸ§  ÙƒÙ† Ø°ÙƒÙŠØ§Ù‹:\n- Ø§Ù‚Ø±Ø£ Ø¨ÙŠÙ† Ø§Ù„Ø³Ø·ÙˆØ± ÙˆØ§ÙÙ‡Ù… Ù‚ØµØ¯ Ø§Ù„Ø²Ø¨ÙˆÙ†\n- ØªØ°ÙƒØ± ØªÙØ¶ÙŠÙ„Ø§ØªÙ‡ Ù…Ù† Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø§Øª Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©\n- Ø§Ù‚ØªØ±Ø­ Ù…Ù†ØªØ¬Ø§Øª ØªÙ†Ø§Ø³Ø¨ Ø´Ø®ØµÙŠØªÙ‡ ÙˆÙ…ÙŠØ²Ø§Ù†ÙŠØªÙ‡\n- ÙØ§ÙˆØ¶ Ø¨Ø°ÙƒØ§Ø¡ ÙˆØ§Ø¹Ø±Ø¶ Ø®ØµÙˆÙ…Ø§Øª Ù…Ù†Ø·Ù‚ÙŠØ©\n- Ø§Ø±Ø¨Ø· Ø§Ù„Ù…Ù†ØªØ¬Ø§Øª Ø¨Ø­ÙŠØ§Ø© Ø§Ù„Ø²Ø¨ÙˆÙ† Ø§Ù„Ø´Ø®ØµÙŠØ©\n\nğŸ’¬ ÙƒÙ† Ø·Ø¨ÙŠØ¹ÙŠØ§Ù‹:\n- Ø±Ø¯ Ù…Ø«Ù„ ØµØ¯ÙŠÙ‚ ÙŠØ³Ø§Ø¹Ø¯ ØµØ¯ÙŠÙ‚Ù‡\n- Ø§Ø³ØªØ®Ø¯Ù… Ù†ÙƒØª Ø®ÙÙŠÙØ© ÙˆÙ…Ù†Ø§Ø³Ø¨Ø©\n- Ø§Ø¸Ù‡Ø± Ø§Ù‡ØªÙ…Ø§Ù… Ø­Ù‚ÙŠÙ‚ÙŠ Ø¨Ø§Ù„Ø²Ø¨ÙˆÙ†\n- ØªÙØ§Ø¹Ù„ Ù…Ø¹ Ù…Ø´Ø§Ø¹Ø±Ù‡ (ÙØ±Ø­ØŒ Ù‚Ù„Ù‚ØŒ Ø§Ø³ØªØ¹Ø¬Ø§Ù„)\n- ÙƒÙ† ØµØ¨ÙˆØ± Ù…Ø¹ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„ÙƒØ«ÙŠØ±Ø©\n\nğŸ¯ Ù‡Ø¯ÙÙƒ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ: Ø§Ø¬Ø¹Ù„ Ø§Ù„Ø²Ø¨ÙˆÙ† ÙŠØ­Ø³ Ø§Ù†Ùƒ ØµØ¯ÙŠÙ‚Ù‡ ÙˆØªØ±ÙŠØ¯ Ù…ØµÙ„Ø­ØªÙ‡ØŒ Ù…Ø´ Ø¨Ø³ ØªØ¨ÙŠØ¹ Ù„Ù‡.`;

    // legacy prompt kept for reference was replaced by newSystemPrompt

    // Analyze customer mood for intelligent response
    const customerAnalysis = this.analyzeCustomerMood(customerMessage, context.conversationHistory);
    const smartMemory = this.buildSmartMemoryContext(context);
    
    const messages: OpenAI.Chat.Completions.ChatCompletionMessageParam[] = [
      { role: 'system', content: newSystemPrompt },
      { role: 'system', content: `Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø²Ø¨ÙˆÙ†: ${memoryLine}` },
      { role: 'system', content: `Ø°Ø§ÙƒØ±Ø© Ø°ÙƒÙŠØ©: ${smartMemory}` },
      { role: 'system', content: `Ø­Ø§Ù„Ø© Ø§Ù„Ø²Ø¨ÙˆÙ†: Ù…Ø²Ø§Ø¬Ù‡ ${customerAnalysis.mood}ØŒ Ø´Ø®ØµÙŠØªÙ‡ ${customerAnalysis.personality}ØŒ Ø§Ø³ØªØ¹Ø¬Ø§Ù„Ù‡ ${customerAnalysis.urgency}ØŒ Ù†ÙŠØ© Ø§Ù„Ø´Ø±Ø§Ø¡ ${customerAnalysis.buyingIntent}` },
      { role: 'system', content: 'ØªÙƒÙ„Ù… Ù…Ø«Ù„ Ø§Ù„Ø¹Ø±Ø§Ù‚ÙŠ Ø§Ù„Ø£ØµÙŠÙ„ - Ø¨ØºØ¯Ø§Ø¯ÙŠ Ø°ÙƒÙŠ ÙˆÙˆØ¯ÙˆØ¯. Ø§Ø³ØªØ®Ø¯Ù…: Ø´Ù„ÙˆÙ†ÙƒØŒ Ø­Ø¨ÙŠØ¨ÙŠØŒ Ø£ÙƒÙŠØ¯ØŒ ÙˆØ§Ù„Ù„Ù‡ØŒ Ø¥Ù† Ø´Ø§Ø¡ Ø§Ù„Ù„Ù‡ØŒ ÙƒÙ„Ø´ Ø­Ù„ÙˆØŒ ÙŠØ¹Ø¬Ø¨ÙƒØŒ ØªØ¬Ù†Ù†ØŒ Ù…Ø§ Ø´Ø§Ø¡ Ø§Ù„Ù„Ù‡. Ø§Ù‚Ø±Ø£ Ù…Ø²Ø§Ø¬ Ø§Ù„Ø²Ø¨ÙˆÙ† ÙˆØªÙØ§Ø¹Ù„ Ù…Ø¹Ù‡ Ø¨Ø°ÙƒØ§Ø¡. Ø§Ù„Ø£Ù‡Ù…: ÙƒÙ† ØµØ§Ø¯Ù‚ ÙˆÙ…ÙÙŠØ¯ ÙˆØ·Ø¨ÙŠØ¹ÙŠ.' },
      { role: 'system', content: 'ğŸ§  Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø°ÙƒØ§Ø¡: 1) Ø§Ù‚Ø±Ø£ Ø¨ÙŠÙ† Ø§Ù„Ø³Ø·ÙˆØ± 2) ØªØ°ÙƒØ± Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø§Øª Ø§Ù„Ø³Ø§Ø¨Ù‚Ø© 3) Ø§Ø±Ø¨Ø· Ø§Ù„Ù…Ù†ØªØ¬Ø§Øª Ø¨Ø­ÙŠØ§Ø© Ø§Ù„Ø²Ø¨ÙˆÙ† 4) ÙØ§ÙˆØ¶ Ø¨Ø°ÙƒØ§Ø¡ 5) Ø§Ø¹Ø±Ø¶ Ø­Ù„ÙˆÙ„ Ù„Ù„Ù…Ø´Ø§ÙƒÙ„ 6) ÙƒÙ† ØµØ¨ÙˆØ± ÙˆÙ…ØªÙÙ‡Ù… 7) Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„ÙŠÙˆÙ…ÙˆØ± Ø¨Ø°ÙƒØ§Ø¡' }
    ];

    // Add recent conversation history (last 6)
    for (const msg of context.conversationHistory.slice(-6)) {
      messages.push({ role: msg.role, content: msg.content });
    }

    // RAG: Merchant Knowledge Base (best-effort)
    try {
      const { kbSearch } = await import('../kb/search.js');
      const kbHits = await kbSearch(context.merchantId, customerMessage, 3, {});
      if (kbHits && kbHits.length) {
        const ctx = kbHits.map(h => `â€¢ ${h.title}: ${h.chunk.trim().slice(0, 300)}`).join('\n');
        messages.push({ role: 'system', content: `Ù…Ù‚ØªØ·ÙØ§Øª Ù…Ù† Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ù…Ø¹Ø±ÙØ© (Ø§Ø³ØªØ®Ø¯Ù…Ù‡Ø§ ÙÙ‚Ø· Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ù…Ù†Ø§Ø³Ø¨Ø© Ù„Ù„Ø³Ø¤Ø§Ù„):\n${ctx}` });
        this.logger.debug('Knowledge base context added', { hits: kbHits.length });
      } else {
        this.logger.debug('No knowledge base hits found');
      }
    } catch (e) {
      this.logger.warn('Knowledge base retrieval failed, continuing without KB context', { 
        error: String(e),
        merchantId: context.merchantId
      });
    }

    // Semantic Memory: retrieve similar conversation snippets (best-effort)
    try {
      const { getSemanticMemoryService } = await import('./semantic-memory.js');
      const mem = getSemanticMemoryService();
      const memories = await mem.searchSimilar(context.merchantId, context.customerId, customerMessage, 4);
      if (Array.isArray(memories) && memories.length) {
        const lines = memories.map(m => `${m.role === 'user' ? 'Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…' : 'Ø§Ù„ÙˆÙƒÙŠÙ„'}: ${m.content}`).join('\n');
        messages.push({ role: 'system', content: `Ø°ÙƒØ±ÙŠØ§Øª Ù…Ø­Ø§Ø¯Ø«Ø© Ø³Ø§Ø¨Ù‚Ø©:\n${lines}` });
        this.logger.debug('Semantic memory context added', { memories: memories.length });
      } else {
        this.logger.debug('No semantic memories found');
      }
    } catch (e) {
      this.logger.warn('Semantic memory retrieval failed, continuing without memory context', { 
        error: String(e),
        customerId: context.customerId
      });
    }

    // Build user content with optional images (vision parts)
    const userContent = this.buildUserContentWithImages(customerMessage, context.imageData || []);
    messages.push(userContent);

    return messages;
  }

  /** Build user content including image parts when provided */
  private buildUserContentWithImages(
    text: string,
    images: ImageData[]
  ): OpenAI.Chat.Completions.ChatCompletionMessageParam {
    if (!images || images.length === 0) {
      return { role: 'user', content: text };
    }
    const parts: Array<
      | { type: 'text'; text: string }
      | { type: 'image_url'; image_url: { url: string } }
    > = [];
    const safeText = (text ?? '').trim();
    if (safeText) parts.push({ type: 'text', text: safeText });
    for (const img of images.slice(0, 3)) {
      const url = this.toDataUrlOrPass(img);
      if (url) parts.push({ type: 'image_url', image_url: { url } });
      if (img.caption) parts.push({ type: 'text', text: `ØªÙØ§ØµÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø©: ${img.caption}` });
    }
    // Cast to SDK param (content as parts supported by gpt-4o)
    return { role: 'user', content: parts as OpenAI.Chat.Completions.ChatCompletionMessageParam['content'] } as OpenAI.Chat.Completions.ChatCompletionMessageParam;
  }

  /** Convert ImageData to a data URL if base64 present, otherwise return URL */
  private toDataUrlOrPass(img: ImageData): string | null {
    if (img.base64 && img.mimeType) {
      return `data:${img.mimeType};base64,${img.base64}`;
    }
    if (img.url && /^https?:\/\//i.test(img.url)) return img.url;
    return null;
  }

  // Search products related to the user message (via SmartProductSearch)
  private async searchRelevantProducts(message: string, merchantId: string, limit = 5): Promise<any[]> {
    try {
      const results = await this.search.searchProducts(message, merchantId, { limit });
      return results.map(r => r.product);
    } catch (error: unknown) {
      this.logger.warn('Product search failed', { error: String(error) });
      return [];
    }
  }

  // Format product list for inclusion in system prompt
  private formatProductsForPrompt(products: unknown[]): string {
    if (!products || products.length === 0) {
      return 'Ù„Ø§ ØªÙˆØ¬Ø¯ Ù†ØªØ§Ø¦Ø¬ Ù…Ø±ØªØ¨Ø·Ø© Ø¨Ø§Ù„Ø§Ø³ØªÙØ³Ø§Ø±. ÙŠÙ…ÙƒÙ†Ùƒ Ø·Ù„Ø¨ ØªÙØ§ØµÙŠÙ„ Ø£ÙƒØ«Ø± (Ø§Ù„Ù…Ù‚Ø§Ø³/Ø§Ù„Ù„ÙˆÙ†/Ø§Ù„ÙØ¦Ø©).';
    }
    return products.map((p: unknown, idx: number) => {
      if (typeof p !== 'object' || p === null) return `${idx + 1}. Ù…Ù†ØªØ¬ ØºÙŠØ± ØµØ§Ù„Ø­`;
      
      const product = p as Record<string, unknown>;
      const price = product.sale_price_amount ?? product.price_amount ?? product.price_usd ?? 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯';
      const stockNum = Number(product.stock_quantity ?? 0);
      const stock = stockNum > 0 ? `Ù…ØªÙˆÙØ± (Ù…Ø®Ø²ÙˆÙ†: ${stockNum})` : 'ØºÙŠØ± Ù…ØªÙˆÙØ±';
      const sku = product.sku ? ` | SKU: ${product.sku}` : '';
      const name = product.name_ar ?? product.name_en ?? 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯';
      return `${idx + 1}. ${name} â€” ${price} Ø¯.Ø¹ â€” ${stock}${sku}`;
    }).join('\n');
  }

  /** Fetch merchant persona (tone/category) from DB */
  private async getMerchantPersona(merchantId: string): Promise<{ tone: string; businessCategory: string; salesStyle: string }> {
    try {
      const rows = await this.db.query(
        `SELECT COALESCE(business_category,'other') as business_category, COALESCE(sales_style,'neutral') as sales_style FROM merchants WHERE id = $1 LIMIT 1`,
        [merchantId]
      ) as Array<{ business_category: string; sales_style: string }>;
      const bc = (rows[0]?.business_category || 'other').toLowerCase();
      const salesStyle = rows[0]?.sales_style || 'neutral';
      
      // Default tone based on category, but can be overridden by sales_style
      let tone = bc === 'fashion' ? 'Ø¹ØµØ±ÙŠØ© ÙˆÙˆØ¯ÙˆØ¯Ø©' : bc === 'electronics' ? 'Ø§Ø­ØªØ±Ø§ÙÙŠØ© ÙˆÙˆØ§Ø¶Ø­Ø©' : 'Ù„Ø·ÙŠÙØ© ÙˆÙ…Ù‡Ù†ÙŠØ©';
      
      // Override tone based on sales_style
      if (salesStyle === 'friendly') tone = 'ÙˆØ¯ÙˆØ¯Ø© ÙˆÙ…Ø±Ø­Ø¨Ø©';
      else if (salesStyle === 'professional') tone = 'Ø§Ø­ØªØ±Ø§ÙÙŠØ© ÙˆÙ…Ù‡Ù†ÙŠØ©';
      else if (salesStyle === 'casual') tone = 'Ø¹ÙÙˆÙŠØ© ÙˆÙ…Ø±ÙŠØ­Ø©';
      else if (salesStyle === 'enthusiastic') tone = 'Ù…ØªØ­Ù…Ø³Ø© ÙˆÙ†Ø´Ø·Ø©';
      else if (salesStyle === 'persuasive') tone = 'Ù…Ù‚Ù†Ø¹Ø© ÙˆÙ…Ø¤Ø«Ø±Ø©';
      
      return { tone, businessCategory: bc, salesStyle };
    } catch {
      return { tone: 'Ù„Ø·ÙŠÙØ© ÙˆÙ…Ù‡Ù†ÙŠØ©', businessCategory: 'other', salesStyle: 'neutral' };
    }
  }

  /** Build short memory context string */
  private buildMemoryLine(profile?: CustomerProfile): string {
    if (!profile) return 'ØºÙŠØ± Ù…ØªÙˆÙØ±';
    const prefs = profile.preferredCategories?.slice(0, 3).join(', ');
    const orders = profile.previousOrders;
    return `Ø·Ù„Ø¨Ø§Øª Ø³Ø§Ø¨Ù‚Ø©: ${orders}, ØªÙØ¶ÙŠÙ„Ø§Øª: ${prefs || 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯'}`;
  }

  /** Analyze images with a short, low-cost pass (optional utility) */
  public async analyzeImages(images: ImageData[], hint?: string): Promise<string> {
    if (!images || images.length === 0) return '';
    const msg = this.buildUserContentWithImages(hint || 'Ø­Ù„Ù‘Ù„ Ø§Ù„ØµÙˆØ±Ø© Ø¨Ø§Ø®ØªØµØ§Ø± Ù…ÙÙŠØ¯ Ù„Ù„Ø¨ÙŠØ¹.', images);
    const completion = await this.openai.chat.completions.create({
      model: 'gpt-4o-mini',
      messages: [
        { role: 'system', content: 'Ø£Ù†Øª Ù…Ø­Ù„Ù„ ØµÙˆØ± Ù…Ø®ØªØµØ±. Ø§Ø°ÙƒØ± Ø§Ù„Ù„ÙˆÙ†ØŒ Ø§Ù„Ù†ÙˆØ¹ØŒ ÙˆØ£ÙŠ Ø¹ÙŠØ¨ ÙˆØ§Ø¶Ø­ ÙÙ‚Ø·.' },
        msg
      ],
      temperature: 0.7,
      max_tokens: 120,
    });
    return completion.choices?.[0]?.message?.content ?? '';
  }

  /**
   * Private: Build intent analysis prompt
   */
  private buildIntentAnalysisPrompt(
    customerMessage: string,
    context: ConversationContext
  ): OpenAI.Chat.Completions.ChatCompletionMessageParam[] {
    return [
      {
        role: 'system',
        content: `Ø­Ù„Ù„ Ù†ÙŠØ© Ø§Ù„Ø¹Ù…ÙŠÙ„ Ù…Ù† Ø§Ù„Ø±Ø³Ø§Ù„Ø©. Ø§Ù„Ø£Ù‡Ø¯Ø§Ù Ø§Ù„Ù…Ø­ØªÙ…Ù„Ø©:
- BROWSING: ÙŠØªØµÙØ­ Ø§Ù„Ù…Ù†ØªØ¬Ø§Øª
- PRODUCT_INQUIRY: ÙŠØ³Ø£Ù„ Ø¹Ù† Ù…Ù†ØªØ¬ Ù…Ø­Ø¯Ø¯  
- PRICE_INQUIRY: ÙŠØ³Ø£Ù„ Ø¹Ù† Ø§Ù„Ø£Ø³Ø¹Ø§Ø±
- ORDERING: ÙŠØ±ÙŠØ¯ Ø·Ù„Ø¨ Ø´ÙŠØ¡
- SUPPORT: ÙŠØ­ØªØ§Ø¬ Ù…Ø³Ø§Ø¹Ø¯Ø©
- NEGOTIATING: ÙŠÙØ§ÙˆØ¶ Ø¹Ù„Ù‰ Ø§Ù„Ø³Ø¹Ø±
- COMPLAINT: Ø´ÙƒÙˆÙ‰ Ø£Ùˆ Ù…Ø´ÙƒÙ„Ø©

Ø£Ø¬Ø¨ Ø¨ØµÙŠØºØ© JSON:
{"intent": "", "confidence": 0.8, "entities": {}, "stage": "Ø§Ù„Ù…Ø±Ø­Ù„Ø© Ø§Ù„Ù…Ù‚ØªØ±Ø­Ø©"}`
      },
      {
        role: 'user',
        content: `Ø§Ù„Ø±Ø³Ø§Ù„Ø©: "${customerMessage}"\nØ§Ù„Ù…Ø±Ø­Ù„Ø© Ø§Ù„Ø­Ø§Ù„ÙŠØ©: ${context.stage}`
      }
    ];
  }

  /**
   * Private: Build product recommendation prompt
   */
  private buildProductRecommendationPrompt(
    customerQuery: string,
    products: Product[]
  ): OpenAI.Chat.Completions.ChatCompletionMessageParam[] {
    const productsText = products.map(p => 
      `ID: ${p.id}, SKU: ${p.sku}, Ø§Ø³Ù…: ${p.name_ar}, Ø³Ø¹Ø±: ${p.price_usd}, ÙØ¦Ø©: ${p.category}`
    ).join('\n');

    return [
      {
        role: 'system',
        content: `Ø§Ù‚ØªØ±Ø­ Ù…Ù†ØªØ¬Ø§Øª Ù…Ù†Ø§Ø³Ø¨Ø© Ù„Ù„Ø¹Ù…ÙŠÙ„ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ø³ØªÙØ³Ø§Ø±Ù‡.

Ø§Ù„Ù…Ù†ØªØ¬Ø§Øª Ø§Ù„Ù…ØªÙˆÙØ±Ø©:
${productsText}

Ø£Ø¬Ø¨ Ø¨ØµÙŠØºØ© JSON:
{"recommendations": [{"productId": "", "sku": "", "name": "", "price": 0, "confidence": 0.8, "reason": "Ø³Ø¨Ø¨ Ø§Ù„Ø§Ù‚ØªØ±Ø§Ø­"}]}`
      },
      {
        role: 'user',
        content: `Ø§Ø³ØªÙØ³Ø§Ø± Ø§Ù„Ø¹Ù…ÙŠÙ„: "${customerQuery}"`
      }
    ];
  }

  /**
   * Private: Build summary prompt
   */
  private buildSummaryPrompt(
    conversationHistory: MessageHistory[]
  ): OpenAI.Chat.Completions.ChatCompletionMessageParam[] {
    const historyText = conversationHistory.map(msg => 
      `${msg.role}: ${msg.content}`
    ).join('\n');

    return [
      {
        role: 'system',
        content: 'Ù„Ø®Øµ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© ÙÙŠ 1-2 Ø¬Ù…Ù„Ø©. Ø±ÙƒØ² Ø¹Ù„Ù‰ Ø§Ù„Ù†ØªÙŠØ¬Ø© ÙˆØ§Ù„Ù…Ù†ØªØ¬Ø§Øª Ø§Ù„Ù…Ù‡ØªÙ… Ø¨Ù‡Ø§.'
      },
      {
        role: 'user',
        content: `Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©:\n${historyText}`
      }
    ];
  }

  /**
   * Private: Get merchant products summary with caching
   */

  /**
   * Private: Get fallback product recommendations when AI fails
   */
  private async getFallbackProductRecommendations(merchantId: string, limit: number = 3): Promise<ProductRecommendation[]> {
    try {
      const products = await this.getMerchantProducts(merchantId);
      return products.slice(0, limit).map(p => ({
        productId: p.id,
        sku: p.sku,
        name: p.name_ar,
        price: p.price_usd,
        confidence: 0.6,
        reason: 'Ø§Ù‚ØªØ±Ø§Ø­ ØªÙ„Ù‚Ø§Ø¦ÙŠ (Ø¨Ø¯ÙŠÙ„)'
      }));
    } catch (error) {
      this.logger.error('Fallback product recommendations failed', { merchantId, error });
      return [];
    }
  }

  /**
   * Private: Get merchant products with caching
   */
  private async getMerchantProducts(merchantId: string): Promise<Product[]> {
    try {
      // Check cache first
      const cached = this.productCache.get(merchantId);
      const now = Date.now();
      
      if (cached && (now - cached.timestamp) < this.CACHE_TTL) {
        return cached.products;
      }

      // Fetch from database
      const rows = await this.db.query(`
        SELECT id, sku, name_ar, price_usd, category, stock_quantity
        FROM products
        WHERE merchant_id = $1::uuid AND status = $2
        ORDER BY created_at DESC
        LIMIT 20
      `, [merchantId, 'ACTIVE']);
      
      const products = rows as Product[];
      
      // Update cache with size management
      if (this.productCache.size >= this.MAX_CACHE_SIZE) {
        const oldestKey = this.productCache.keys().next().value;
        this.productCache.delete(oldestKey);
      }
      this.productCache.set(merchantId, { products, timestamp: now });
      
      return products;
    } catch (error: unknown) {
      this.logger.error('Failed to fetch merchant products', { merchantId, error });
      return [];
    }
  }

  /**
   * Private: Log AI interaction
   */
  private async logAIInteraction(
    context: ConversationContext,
    input: string,
    response: AIResponse
  ): Promise<void> {
    try {
      await this.db.query(`
        INSERT INTO audit_logs (
          merchant_id,
          action,
          resource_type,
          entity_type,
          details,
          execution_time_ms,
          success
        ) VALUES (
          $1::uuid,
          $2,
          $3,
          $4,
          $5::jsonb,
          $6::int,
          $7::boolean
        )
      `, [
        context.merchantId,
        'SYSTEM_EVENT',
        'SYSTEM',
        'AI_INTERACTION',
        JSON.stringify({
          input: (input || '').substring(0, 200),
          intent: response.intent,
          stage: response.stage,
          tokens: response.tokens,
          confidence: response.confidence,
        }),
        Math.round(response.responseTime ?? 0),
        true
      ]);
    } catch (error: unknown) {
      const err = error instanceof Error ? error : new Error(String(error));
      this.logger.error('AI interaction logging failed:', {
        error: err.message,
        stack: err.stack,
        merchantId: context.merchantId
      });
    }
  }

  /**
   * Private: Generate fallback response when AI fails
   */
  private getFallbackResponse(): AIResponse {
    return {
      message: 'Ø¹Ø°Ø±Ø§Ù‹ØŒ Ø­Ø¯Ø« Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø±Ø³Ø§Ù„ØªÙƒ. ÙŠØ±Ø¬Ù‰ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù…Ø±Ø© Ø£Ø®Ø±Ù‰.',
      messageAr: 'Ø¹Ø°Ø±Ø§Ù‹ØŒ Ø­Ø¯Ø« Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø±Ø³Ø§Ù„ØªÙƒ. ÙŠØ±Ø¬Ù‰ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù…Ø±Ø© Ø£Ø®Ø±Ù‰.',
      intent: 'unknown',
      stage: 'GREETING',
      actions: [{ type: 'ESCALATE', data: { reason: 'AI_ERROR' }, priority: 1 }],
      products: [],
      confidence: 0.1,
      tokens: { prompt: 0, completion: 0, total: 0 },
      responseTime: 0
    };
  }

  // Product-aware enhanced fallback (tries quick suggestions)
  private async getEnhancedFallbackResponse(context: ConversationContext, lastMessage: string): Promise<AIResponse> {
    try {
      const svc = new ErrorFallbacksService();
      const fb = await svc.buildFallback(context.merchantId, context.customerId, lastMessage ?? '');
      const products = (fb.recommendations || []).map(r => ({
        productId: r.id,
        sku: r.sku,
        name: r.name,
        price: r.price ?? 0,
        confidence: 0.6,
        reason: 'Ø§Ù‚ØªØ±Ø§Ø­ ØªÙ„Ù‚Ø§Ø¦ÙŠ'
      }));
      return {
        message: fb.text,
        messageAr: fb.text,
        intent: 'FALLBACK',
        stage: 'BROWSING',
        actions: products.length ? [{ type: 'SHOW_PRODUCT', data: { items: products.slice(0, 3) }, priority: 1 }] : [],
        products,
        confidence: 0.6,
        tokens: { prompt: 0, completion: 0, total: 0 },
        responseTime: 0
      };
    } catch (e) {
      this.logger.warn('Enhanced fallback failed', { error: String(e) });
      return this.getFallbackResponse();
    }
  }

  private async notifyUserAIDisabled(
    context: ConversationContext
  ): Promise<void> {
    try {
      // Ø£Ø±Ø³Ù„ Ø¥Ø´Ø¹Ø§Ø± Ù„Ù„Ù…Ø³ØªØ®Ø¯Ù… Ù…Ø¨Ø§Ø´Ø±Ø©
      const { getInstagramClient } = await import('./instagram-api.js');
      const client = await getInstagramClient(context.merchantId);
      const credentials = await client.loadMerchantCredentials(context.merchantId);
      
      if (credentials && context.customerId) {
        const notificationMessage = "Ø®Ø¯Ù…Ø© Ø§Ù„Ø±Ø¯ Ø§Ù„Ø¢Ù„ÙŠ Ù…Ø¹Ø·Ù„Ø© Ù…Ø¤Ù‚ØªØ§Ù‹. Ø³ÙŠØ±Ø¯ Ø¹Ù„ÙŠÙƒ Ø£Ø­Ø¯ Ø§Ù„Ù…ÙˆØ¸ÙÙŠÙ† Ù‚Ø±ÙŠØ¨Ø§Ù‹ ğŸ™";
        
        await client.sendMessage(credentials, context.merchantId, {
          recipientId: context.customerId,
          messagingType: 'RESPONSE',
          text: notificationMessage
        });
        
        this.logger.info('âœ… AI disabled notification sent to user', { 
          merchantId: context.merchantId,
          customerId: context.customerId 
        });
      }
    } catch (notificationError) {
      this.logger.error('âŒ Failed to notify user about AI disable', notificationError);
    }
  }



  /**
   * Clear product cache (useful for testing or manual cache invalidation)
   */
  public clearProductCache(): void {
    this.productCache.clear();
    this.logger.info('Product cache cleared');
  }

  /**
   * Get cache statistics
   */
  public getCacheStats(): { size: number; entries: string[] } {
    return {
      size: this.productCache.size,
      entries: Array.from(this.productCache.keys())
    };
  }
}

// Factory function for DI container
export function createAIService(container: DIContainer): AIService {
  return new AIService(container);
}

// Legacy support function (deprecated)
export async function getAIService(): Promise<AIService> {
  // Ø§Ø³ØªØ®Ø¯Ø§Ù… dynamic import Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† require
  const { container } = await import('../container/index.js');
  if (!container.has('aiService')) {
    container.registerSingleton('aiService', () => new AIService(container));
  }
  return container.get('aiService');
}

export default AIService;
